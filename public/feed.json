{
    "version": "https://jsonfeed.org/version/1",
    "title": "Blog - James Little",
    "home_page_url": "https://jameslittle.me",
    "feed_url": "https://jameslittle.me/rss/feed.json",
    "icon": "https://jameslittle.me/logo.svg",
    "author": {
        "name": "James Little",
        "url": "https://jameslittle.me"
    },
    "items": [
        {
            "id": "https://jameslittle.me/blog/2023/winding-down-stork",
            "content_html": "<article><p>Hi, friends.</p><p>I'm no longer able to work on Stork to the degree the project and its users deserve, and because of this, I will be stopping my Stork development and support for the foreseeable future.</p><p>I've shut down any mechanism through which people can give me money for working on Stork (i.e. Ko-Fi and the &quot;buy a sticker&quot; page), I've archived many auxiliary repositories related to the project, and I'll be closing the Discord server by the end of the month.</p><p>Stork has been intertwined with my life for the past four years, and I'm simultaneously happy with all I've been able to build and design, and bummed that I was not and am not able to give it the features, community, and development pace it deserved. I'm extremely grateful to everyone who has used Stork. This project has introduced me to many interesting people around the world, and I'm thankful for all of you that I've gotten to know.</p><p>Thank you for supporting me and for using Stork, and I hope to see you around in the future.</p><h2>FAQs</h2><p><strong>What should I use for client-side search?</strong></p><p>Oh boy, there are a ton of great options. <strong><a href=\"https://github.com/tinysearch/tinysearch\">Tinysearch</a></strong> and <strong><a href=\"https://pagefind.app/\">PageFind</a></strong> are, philosophically, the most similar alternatives to Stork. <strong><a href=\"http://lunrjs.com/\">Lunr</a></strong>, <strong><a href=\"http://fusejs.io/\">Fuse.js</a></strong>, and <strong><a href=\"https://github.com/lucaong/minisearch\">Minisearch</a></strong> are similar, but are Javascript-only (no WASM). <strong><a href=\"http://meilisearch.com/\">Meilisearch</a></strong>, <strong><a href=\"https://github.com/wilsonzlin/edgesearch\">EdgeSearch</a></strong>, and <strong><a href=\"https://github.com/quickwit-oss/tantivy\">Tantivy</a></strong> are all server-hosted search engines written in Rust. I haven't tried any of them for any significant amount of time, but they all seem like useful projects.</p><p><strong>Will the Stork files continue to be hosted from <a href=\"http://files.stork-search.net/\">files.stork-search.net</a>?</strong></p><p>Yes, I plan on keeping the Stork CDN up for at least four years, starting today. I currently have no reason or incentive to take the files down, and my AWS bill is &lt;$1/mo, so my plan is not necessarily to shut down the CDN after four years, but instead to reevaluate the decision and see if it makes sense to continue hosting the files or if instead, I should make plans to shut down the CDN.</p><p>Regardless of what happens, I'll give users six months of notice here on Github Discussions before shutting down the CDN.</p><p><strong>Will the documentation remain available?</strong></p><p>Yes, the content currently available on <a href=\"https://stork-search.net/\">https://stork-search.net</a> will be available for as long as the Stork CDN files are up, if not longer.</p><p><strong>Will security vulnerabilities be patched?</strong></p><p>Reported security vulnerabilities will be investigated on a case-by-case basis, and I can't make any guarantees about my ability to fix or publish security patches.</p><p><strong>Is Stork completely abandoned? Can I still submit pull requests?</strong></p><p>My current thinking is that I'm not going to do any more development or support for the foreseeable future, but that doesn't mean that I'm dropping off the face of the earth. If folks are interested in contributing, I'll review, merge, and release human-authored pull requests with similar discretion that I do today (in other words, I probably won't merge pull requests that significantly diverge from the philosophy of the project). I'm also happy to chat about the project with people who are hoping to contribute.</p><p><strong>Will someone else take over Stork?</strong></p><p>Today, I don't plan on transferring maintainership of Stork to anyone else or adding anyone else as a maintainer, but should someone express a willingness and ability to take over the project, I'll consider it.</p><p><strong>What about forks?</strong></p><p>Please take what you can from the Stork source code! I'll publish all my work-in-progress 2.0.0 branches so people can poke around, and if I have the time and energy, I'll extract some of the more interesting bits into their own repositories to give them a bit more spotlight. You are welcome to fork the Stork source code and start your own project, community, etc. - I'll be cheering you along from the sidelines if you do!</p><p>Please don't co-opt the Stork branding (logo, color, imagery, etc) in your fork, and, until your fork significantly diverges, please mention that it's a fork of Stork.</p><p><strong>Is this open-source burnout?</strong></p><p>Probably, a little bit. Aside from the day job, this is the largest project I've ever been a part of, and the only one that I've done completely by myself. Stork has a binary component and a web library, there's a documentation site, a UI theming system, a rich feature set for parsing different kinds of documents from different sources, a home-grown algorithm for writing a search index to disk, and a complex system for loading those search indexes from the web UI. I've learned a lot about how to manage the scope of a solo-run open source web library, especially one that can only take up a few hours of each week.</p><p>For as long as I can remember I've had more ideas than I have had time, and it's been tiring to continuously gauge the priority those ideas against stewarding the project well.</p><p><strong>What's next for James?</strong></p><p>There's no big coding project waiting in the wings that I'm going to drop. I have a day job and a wedding to plan, and while those things will probably take up most of my focus in the near future, I'm keeping some time open to tinker and explore. I love programming and designing and building, so regardless of what form it takes, I'm confident there will be all of that in my future.</p><p><strong>AMA</strong></p><p>I tried to think of everything I'd want to know about, but if you have any more questions about this post, about Stork, or about anything else, please drop them in <a href=\"https://github.com/jameslittle230/stork/discussions/360\">the Github discussion's comments</a>, reach out on Mastodon (@jil@mastodon.social), or send me an email.</p><p>Thank you for everything,<br>James</p></article>",
            "url": "https://jameslittle.me/blog/2023/winding-down-stork",
            "title": "Winding Down my Work with Stork",
            "summary": "I'll be stopping Stork development and support for the foreseeable future.",
            "date_modified": "2023-06-18T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2023/2022-review",
            "content_html": "<article><p>I didn't accomplish a lot of what I hoped to do. I ran less than any other year prior since 2011, and didn't manage to run a 5k under 23 minutes. I didn't release Stork 2.0.0 or publish my blog redesign or start swimming again. I didn't travel except for work, I didn't journal, and I didn't solidify any new hobbies or passions.</p><p>But I'm happy about how the year went! I had a really gratifying job change at work, I spent more energy seeing my friends (and feel like it paid off), I started attending Shabbat services at the synagogue down the street. I took some cool photos and fostered some friendships while doing so. I paid more attention to planning and anticipating the future, which cut down on stress. I started budgeting, I got engaged (!!), I worked on my mental health, and I stepped away from social media.</p><p>I'm feeling grateful for 2022 went and excited about 2023!</p></article>",
            "url": "https://jameslittle.me/blog/2023/2022-review",
            "title": "2022",
            "summary": "A quick review.",
            "date_modified": "2023-01-01T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2022/new-wave-js-frameworks",
            "content_html": "<article><p>I don't think I really <em>get</em> the new wave JS frameworks (namely Remix.run and Next.js, but Gatsby might fit there too, if it's still relevant).</p><p>I'm trying to balance my thoughts against being all &quot;old man yells at cloud&quot; here, but either these frameworks are way overcomplicating things, or they're skating to where the puck is going to be, and I'm not there yet.</p><p>What wigs me out about these frameworks is that they don't really let you see what's going on with the server side of things. You write some React code, then deploy it to some third party service that's built on top of Lambda functions + a CDN, and then... you have a website. Good luck peeking under the hood to see what code is running where, because these cloud services won't show you the actual service it's hosting for you, and it's all minified Javascript anyway.</p><p>I wish that these frameworks would build a client bundle and a server bundle locally, and I could decide what to do with them. Like, maybe I could upload them both to some sort of VPS, set up nginx in the right way, and have myself a mostly-static site and a backend type thing, both derived from the same React-ish source code. Or I could upload both to Netlify or Vercel and get all the global distribution and caching that their infrastructure handles. But as it stands, none of these frameworks want you to think too hard about what happens between pushing to your Git remote and when they deploy your stuff, because they're doing a ton of optimization in between in the name of speed.</p><p>I think when I first started using them I was surprised that there needed to be any server deployments at all? I shouldn't need any Lambda functions to run a static site, and I don't think the feature that replaces all links with Javascript that replaces one page's DOM with another page's DOM is worth needing a whole backend. I know it makes the website faster, but still.</p><Note title=\"Update\"><p><a href=\"https://www.arcana.computer\">Justin</a> pointed out that this is a setting that Next.js supports! I think when I originally tried their Static HTML Export setting, there was some issue with deploying the final output to Netlify, but I'll have to check back in there. If you're okay being on the non-standard path and losing <a href=\"https://nextjs.org/docs/advanced-features/static-html-export#unsupported-features\">some features</a>, this might be a viable choice.</p></Note><p>These frameworks have powerful enough marketing arms (and sparse enough documentation) that I also can't figure out if either one is <em>meant for me</em> or not. When I run into rough edges, nothing is there to tell me that I'm doing something wrong or that they just haven't put enough work into that part of the framework or that I'm just not the type of website builder that they're trying to capture in their potential market, because nothing incentivizes the people building these frameworks to write documentation discouraging people from using them.</p><p>I've been spending some time working on a redesign of this site, and I'm happy with the visual language I've put together, but I'm not really excited about building it out in any of the <a href=\"https://www.11ty.dev/docs/languages/\">templating languages available to me in Eleventy</a>—I like the idea of building out my UI in React/JSX, and having the framework know what can be server-side-rendered and what it should hydrate on the client. But it seems like once you want that, you have to deal with the server-side mystery meat of the new wave JS frameworks.</p></article>",
            "url": "https://jameslittle.me/blog/2022/new-wave-js-frameworks",
            "title": "Some angst around modern JS frameworks",
            "summary": "I don't think I really get the \"new wave\" JS frameworks. I think they produce build artifacts that are optimized for the wrong thing.",
            "date_modified": "2022-07-04T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2022/data-driven-pull-requests",
            "content_html": "<article><p>One of the core values of the <a href=\"https://stork-search.net\">Stork</a> project is that it respects the end user's experience.</p><p>More concretely, this means that:</p><ol><li>Searches should feel fast,</li><li>Embedding Stork shouldn't slow down the hosting webpage, and</li><li>Loading a search index shouldn't take longer than is necessary.</li></ol><p>In practice, this requires that, during development, I keep track of certain metrics that affect the end-user experience, making sure they stay at an acceptable level. For example, the size of a search index should be small so that a client can download it quickly and hold less data in memory once it's been loaded. The search algorithm should be fast, so that there isn't latency between typing something into the search box and getting a result. These are the metrics that, in theory, separate Stork from other, similar services and justify using lesser-proven technologies (like Rust compiled to WASM) where, perhaps, something more customary (filtering a JSON blob with Javascript) would have worked instead.</p><p>The Stork project, though, has room to improve on nearly every measurable metric. I'd love for Stork in two years to produce smaller index files, perform faster searches, and build indexes faster than it does today. As I make changes, I want to make sure that those metrics are, in general, trending in the right direction.</p><p>In this post, I'll describe how I set up the infrastructure to track and display metric changes on a per-pull-request basis, and describe how that infrastructure changes my flow of developing new features.</p><h2>Measure what can be measured</h2><p>The first step to making data-driven pull requests is collecting the data necessary. As of this writing, Stork has two types of metrics: build artifact file sizes, and algorithm speed benchmarks. Here's the data I track:</p><ul><li>Build artifact file sizes<ul><li>The size of <code>stork.js</code></li><li>The size of <code>stork.wasm</code></li><li>The size of <code>federalist.st</code>, a sample search index built from the federalist papers, with no other config settings customized</li></ul></li><li>Algorithm speed benchmarks<ul><li>The duration of an end-to-end search for a single word</li><li>The duration of an index build</li></ul></li></ul><p><a href=\"https://crates.io/crates/criterion\">Criterion.rs</a>, a benchmark framework for Rust code, runs in CI to measure the algorithm speed benchmarks. Python's <code>os.path.getsize()</code> measures the build artifact file sizes.</p><p>I've written a script that will run all my tests and output a JSON blob with a single data point for each:</p><pre data-language=\"json\">{\n  search_duration: 0.25,\n  build_duration: 4.1,\n  stork_wasm_filesize: 12.82,\n  ...\n}\n</pre><p>It's important that this script be able to run in CI successfully for every commit so that I can run this on any arbitrary commit <Footnote>Any arbitrary commit <em>after I've added this script</em>, of course.</Footnote> and get results representative of the state of the world at that moment in Git history. Therefore, I've made it a requirement that this script return successful output in CI for every pull request; if it can't run or doesn't succeed, I treat that as a unit test failure and Github won't let me merge the PR. When combined with a strict &quot;only squash-and-merge allowed&quot; policy, this means that, for every commit on <code>master</code>, I can know that I can run my benchmarking script and it will succeed.</p><h2>Compare measurements automatically</h2><p>To understand the impact of a pull request, I want to know how each of my metrics compares before the patch is applied, then after a patch is applied. If I have a PR where I'm trying to shrink the typical index size, no matter how successful I am at shrinking the index it shouldn't be acceptable if it also slows down searches by an order of magnitude.</p><p>I've built (er, cobbled together from multiple sources) a script that runs in CI, along with my unit tests and linters, that does the following:</p><ol><li>Fetches the base SHA for the PR it's acting upon</li><li>Runs the benchmarking script, ensures it succeeds, and writes its output to a tempfile</li><li>Checks out the PR's base SHA and recompiles the project</li><li>Runs the benchmarking script again, ensures it succeeds, and writes its output to a different tempfile</li><li>Runs a script to compare the JSON blobs in the two tempfiles, determining the percentage change for each of the values</li><li>Comments on the PR with those percent changes, letting me judge the impact of the PR. (There's some fanciness where it'll update the comment if it sees that it's already commented.)</li></ol><Image src=\"https://files.jameslittle.me/images/data-driven-pull-requests/github-comment.png\"></Image><p>You might be asking, &quot;Why does the CI job need to run the script twice? Isn't it already running the script for every commit? Can't it save those values somewhere?&quot;</p><p>Good question. For better or for worse, Stork uses Github Actions as its continuous integration service. Running benchmarks on shared machines is unreliable - invoking the same script on the same commit hash can result in wildly different benchmark durations, because the shared machines that Github Actions offers can be under arbitrary amounts of load at a given time. (I've seen the same benchmark on the same git commit vary by a 20% buffer!) Therefore, comparing incoming benchmark values with preexisting benchmark values will be bad science, since I can't isolate all the variables that are going into the benchmark times.</p><p>It's not perfect, but I try to isolate for this jitter by running the two comparison benchmarks in direct sequence, on the same machine, during the same Github Actions job. There's still some jitter (you see it in the <code>1.02x</code> in the screenshot above), but much less. I also only keep the raw duration values around as a sanity check - I never really perform any action based on those values.</p><h2>The impact on Stork's development process</h2><p>There's a cost to running this system: CI takes much longer for every PR. Even so, I've found it to be &quot;worth it&quot; - these metrics let me create data-driven decisions for each pull request that I wasn't making before. Even though the tools were all available for me to make this comparison on my own, the automatic Github report has changed by development behavior.</p><p>With this system in place, I'm much less afraid of experimentation. If I have an idea for an optimization, I'll put up a PR that hacks it together. If one of my metrics goes in a bad direction, I'll know that it's not worth continuing to pursue. I've also started putting up competing PRs that both solve the same problem in different ways, which lets me explore and compare both solutions in parallel and then have less uncertainty when I decide to move forward with one over the other.</p><p>In a more <em>emotional</em> sense, I also have more energy to make optimizations with this system in place, since the impact of my work is made very clear to me. Putting up a PR that reduces search duration by 5% is notable, and it's nicer to anticipate being able to celebrate that when I'm in the throes of algorithm optimization. It's nice to see improvements, dangit, and it makes the work I put in worth it.</p><p>In summary: data is good, and it feels exciting to drive metrics in one direction. Anything I can do to add that those warm fuzzies by seeing a number go down after putting in the work is a welcome addition to my life.</p><h2>Appendix: How it all works</h2><ul><li><a href=\"https://github.com/jameslittle230/stork/blob/714698991465328fc06cef2654a2cff9d88ce71c/scripts/generate_stats.py\">This script runs the benchmarks—both Criterion and filesize—and outputs a JSON object.</a></li><li><a href=\"https://github.com/jameslittle230/stork/blob/714698991465328fc06cef2654a2cff9d88ce71c/scripts/compare_stats.py\">This script compares two JSON objects and generates the HTML for a Github comment.</a></li><li><a href=\"https://github.com/jameslittle230/stork/blob/714698991465328fc06cef2654a2cff9d88ce71c/.github/workflows/ci-on-push.yml#L122-L159\">This part of my Github Actions file orchestrates the benchmark runs, runs the comparison script, and publishes the Github PR comment.</a></li></ul></article>",
            "url": "https://jameslittle.me/blog/2022/data-driven-pull-requests",
            "title": "Data Driven Pull Requests",
            "summary": "My system for running comparative benchmarks for Stork patches, and how it helps make sure Stork moves in the right direction.",
            "date_modified": "2022-05-03T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2021/2021-work-setup",
            "content_html": "<article><p>As of August 2021, I officially work from Stripe's &quot;Remote Hub&quot; after being based in the San Francisco office since I started two years prior. I recently moved to the Boston area, a location where Stripe doesn't have an office. We moved into a two-bedroom apartment and turned one of those bedrooms into a joint office, where I do work during the day and where my girlfriend does schoolwork in the evening.</p><p>Anyway. I'm officially remote now, and Stripe gives its remote employees a bit of money to set up their workspace. I find these types of post interesting, and I feel like I've done well with my setup and it might be worth sharing. Here's how I set up my area of the office.</p><Figure caption=\"The whole thing\" layout=\"wide\"><Image src=\"https://files.jameslittle.me/images/2021-desk-post/DSC05389.jpg\"></Image></Figure><h2>The Desk</h2><Figure layout=\"wide-half-left\"><Image src=\"https://files.jameslittle.me/images/2021-desk-post/DSC05387.jpg\"></Image></Figure><p>The desk itself is a <a href=\"https://www.homedepot.com/p/HARDWOOD-REFLECTIONS-Unfinished-European-Walnut-4-ft-L-x-25-in-D-x-1-5-in-T-Butcher-Block-Countertop-152550HDBW-50/304632170\">butcher block from Home Depot</a>. It's not terribly large, just 2' x 4', but I'm the kind of person who will spread all my things over whatever size surface you give me, so I keep it small to reduce spread opportunities. <Footnote>Also, it was the largest desk that fit in our San Francisco apartment.</Footnote> At some point during the pandemic, I put it on some sit-stand legs. They're <a href=\"https://www.fully.com/standing-desks/jarvis-frame-only.html\">Fully legs</a>, but the brand doesn't matter—from what I can tell, a bunch of companies make the same sort of thing, if my YouTube recommendations are accurate. I stand in the mornings and sit when I'm tired. Sometimes I sit the whole day. They're not the most aesthetically pleasing table legs, but being able to stand sometimes keeps me marginally healthier.</p><p>The problem with sit-stand desks is that it makes cable-management about five times more difficult. The best cable-management system I've found (that <a href=\"https://www.youtube.com/watch?v=pkuxIy3kFZM\">MKBHD mentioned</a> in his 2021 studio tour) is setting everything up when the desk is standing, bundling all the cables that go down to the ground with velcro ties, and then letting that big cord of cables bend when the desk lowers. To reduce the number of cables I have that go down to the ground, I've mounted a power strip to the underside of my desk, and mounted cable catchers around the power strip, so ideally the only wires snaking down from my desk to the ground is power and ethernet. The cable catchers are a mess, but they're not terribly visible, so luckily I can forget about the bad cable management until I have to make adjustments.</p><h2>Monitors &amp; Computers</h2><p>I usually end up with two to four windows tiled on the primary monitor and two more tiled vertically on the secondary monitor. Remember the thing I said about spreading things out over an entire surface? I do the same thing with my digital desktop, too. I end up liking to look at tons of different things at the same time—I've tried to be the kind of person who closes out windows and tabs, but I don't think that'll ever really take.</p><p>Because my desk isn't terribly large, I try to mount as many things to its edge as I can to give myself as much usable surface space as I can. The two most important things I mount are my monitors. I use two monitors. The first is an <a href=\"https://www.lg.com/us/monitors/lg-27UL500-W-4k-uhd-led-monitor\">LG 27UL500</a>, a 27&quot; 4K monitor that was standard-issue in the Stripe offices of 2019. On its left, rotated vertically, is a <a href=\"https://pcmonitors.info/reviews/dell-p2415q/\">Dell P2415Q</a>, a 24&quot; 4K monitor that was my primary until I realized that this pandemic was probably going to last a while. They live on two independent arms clamped to the back of my desk, so they take up ~no desk space and I can use the entire area underneath them to put other stuff. I have no complaints with either (except for the fact that I only get 30 FPS on the 24&quot; one—I think it's because I'm using an HDMI connection instead of a DisplayPort one), but I'm looking forward to the ever-rumored general purpose Apple monitor that everyone hopes is getting released soon.</p><Note title=\"March 2022 update\"><p>I upgraded to an M1 Pro 14&quot; Macbook Pro for both my personal and work computer, making the next paragraph redundant. I think I didn't find the laptop → desktop transition jarring because the 16&quot; computers I had been using previously were so chunky that it was kind of annoying to take them from place to place. It's much nicer to have a 14&quot; laptop that I can use from the couch or throw in my bag.</p></Note><p>I have two computers on my desk: my personal computer and my work laptop. I got an M1 Mac Mini (16 GB memory, 1 TB storage) pretty much immediately after the Apple event when they were announced, and it absolutely screams through anything I throw at it. I got the Mac Mini because it was the only M1 machine that could drive two external displays. At first, I was nervous about switching to a desktop-only machine after using laptops for nearly ten years, but it hasn't been nearly as disruptive as I expected.<Footnote>I still keep my old laptop kicking around when I really need it, but the aforementioned pandemic has reduced the number of times I need to bring a computer from place to place. Once that computer dies, I'll pick up one of the new Macbook Pros—you should be impressed with the self-control I've exhibited in not buying one yet.</Footnote> My work laptop lives in a vertical stand and I pretty much constantly use it in clamshell mode, mostly to save space.</p><Figure layout=\"wide\"><Image src=\"https://files.jameslittle.me/images/2021-desk-post/DSC05397.jpg\"></Image></Figure><p>Connected to that computer is a <a href=\"https://www.caldigit.com/ts3-plus/\">Caldigit TS3</a>, which is a fantastic Thunderbolt hub. Every day, I take the wire coming out of the Caldigit and move it between the Mac Mini and the work laptop. <Footnote>Technically, I also switch the input on the vertical 24&quot; monitor from DisplayPort to HDMI. See, the M1 Mac Mini can only power two monitors if they're both connected to the on-device IO, so I keep an HDMI cable between that monitor and the Mac Mini, and a DisplayPort --&gt; USB-C cable between it and the work laptop. It's fine, but I'd be excited to upgrade to a personal computer that can drive two monitors from the Caldigit so I'd only have to do <em>literally one thing</em> to switch between the two machines.</Footnote> That Caldigit connects to my AV setup, to my wired ethernet, and to my keyboard, trackpad, and wireless mouse transponder, and gives me a place to plug in my SD cards when I need to import photos and a place to plug in extra USB stuff. This thing is rock solid and looks relatively nice-looking—I'd recommend it.</p><h2>Peripherals</h2><Image src=\"https://files.jameslittle.me/images/2021-desk-post/DSC05391.jpg\"></Image><p>I don't think I have RSI, but I've definitely noticed that when I spend too much time using a trackpad or a normal-looking mouse, my right hand thumb and pointer finger start really hurting. Switching to the MX Vertical took away nearly all of that pain, so I use that as my mouse. I had some awful connection blips when I was connecting my mouse to my computer using Bluetooth, but once I plugged in a Logitech Unifying Reciever into the Caldigit TS3 and used that to bridge the wireless gap, 90% of those blips went away. I learned that I'm really sensitive to mouse connection blips—I don't notice it happening in the moment, but after a day of poor connection, I'm noticably frustrated. Thanks, Logitech Unifying Receiver.</p><p>I use macOS exclusively, and there are some pretty nice affordances in that OS for trackpad use, so also use a Magic Trackpad to whip out a multifinger gesture or some smooth omnidirectional scrolling when I need it.</p><Image src=\"https://files.jameslittle.me/images/2021-desk-post/DSC05390.jpg\"></Image><p>Until only a few weeks ago, I used a white <a href=\"https://drop.com/buy/vortex-poker-iii-compact-keyboard\">Poker 3</a> with Cherry MX Clear switches, with <a href=\"https://drop.com/buy/massdrop-x-mito-canvas-xda-custom-keycap-set\">Massdrop xx MiTo keycaps</a>, which I started using in 2016. Very recently, I picked up a <a href=\"https://www.zsa.io/moonlander/\">ZSA Moonlander</a> secondhand, and have been trying to integrate it into my setup to prevent myself from slouching as much while I work. I think I have a love-hate relationship with this thing: I can feel how it's ergonomically nice to use, but I have to re-learn how to type: the board's ortholinear layout messes me up with the letters, and the funky (er, custom) special character placement messes me up with everything else. I've dropped from a consistent 90 WPM to about 40 after a week of having this thing, but I'll post some updates on Twitter if I give up or go back to the Poker 3.</p><p>I absolutely love having a keyboard I can configure. ZSA hosts a tool called <a href=\"https://configure.zsa.io\">Oryx</a>, which seems to be a nice web UI to configure its QMK-based firmware. I've been enjoying tweaking the setup, moving characters to the places it &quot;feels&quot; like they should live, getting tricky with my layers and my hold vs. tap keys. I probably reflash this keyboard about 3x/day. <a href=\"https://configure.zsa.io/moonlander/layouts/AbLb0/latest/0\">This is my layout</a>—that link should hopefully remain stable so it shows you what I'm currently working with, long after I've published this post.</p><h2>AV</h2><p>When I moved away from San Francisco, I realized that most of my interactions with people at work would take place on a video call <Footnote>I also <a href=\"https://twitch.tv/jameslittle230\">infrequently stream live-coding on Twitch</a>, so investing in the AV desk setup helps there, too.</Footnote>, so it was important to me that I level up my video call setup. (I also was really into filmmaking at one point in my life, so investing in my video call setup would scratch the audio &amp; video gear itch that never really seems to go away). I want people to hear and see me well so that they don't feel removed when talking to me, and I kind of like flexing with my nice setup.</p><h3>Microphone</h3><p>For a while, I used a Blue Yeti, but wanted to upgrade when I started getting feedback that it was very distance-sensitive (in that when I naturally moved around when talking, the volume would duck out when I moved my head farther away) but also somehow too sensitive to background noise like trucks or leafblowers. I also wanted to see if I could get better sound quality with an XLR microphone, so when I moved to Boston, I switched.</p><Image src=\"https://files.jameslittle.me/images/2021-desk-post/IMG_5827.jpg\"></Image><p>Today, I use a <a href=\"https://www.rode.com/podmic\">Rode PodMic</a>. It sounds a whole lot better than the Blue Yeti (in my opinion), and when I put the Rode pop filter over it (per <a href=\"https://www.youtube.com/watch?v=NFzVwl2N0iA\">Tom Buck's suggestion</a> I can almost imagine that it sounds like a Shure SM7B. I keep it mounted on a stand clamped to the back of my desk; the stand isn't a <a href=\"https://www.bhphotovideo.com/c/product/484972-REG/Rode_PSA1_PSA_1_Studio_Boom_Arm.html?sts=pi-ps&amp;pim=Y\">Rode PSA1</a>, but if I were to start over, that's what I would get. When I'm talking, I swing it out so it's about six inches from my mouth (unfortunately blocking my view of the vertical second monitor), but when I'm not talking it hangs out at the side of my desk.</p><Note title=\"March 2022 update\"><p>When I got new computers, I put the microphone on the other side of my desk. I also got the first-party wind screen for the Podmic which makes it sound slightly nicer, and (finally) got the PSA1.</p></Note><p>The Rode PodMic is an XLR microphone, so it needs to go into a USB audio interface to connect to my computer. It works well with the <a href=\"https://focusrite.com/en/audio-interface/scarlett/scarlett-solo\">Focusrite Scarlett Solo</a>, though the Focusrite's gain knob has to be turned up to nearly the maximum. The Focusrite connects to my CalDigit dock, which connects to my computer, and it works just like any audio input. This setup has been rock solid, and I've gotten much improved reviews from people on the other end of the video calls.</p><Image src=\"https://files.jameslittle.me/images/2021-desk-post/DSC05398.jpg\"></Image><h3>Camera</h3><p>When creating videos, I've learned that audio quality is much more important than video quality, so I spent most of my energy optimizing that setup. However, very recently, I was feeling the Elgato Cam Link itch, and wanted to upgrade from the Logitch webcam I was using throughout the pandemic. Instead of getting the Cam Link, I found the <a href=\"https://www.bhphotovideo.com/c/product/1609628-REG/kanexpro_con_gamecap_hdmi_4k_usb_2_0.html\">KanexPro HDMI capture dongle</a> at MicroCenter and, on a whim, connected it to the camera I use for photography: a <a href=\"https://www.dpreview.com/products/sony/slrs/sony_a6300\">Sony a6300</a>. It worked perfectly—I got lucky that the Sony camera I have is one that works well when connected to a capture card, since that's not the case for all the digital cameras out there. When the Sony is hooked up to the desk setup, I obviously can't use it for photography, but it's easy enough to pop it out when I want to take some real pictures.</p><Image src=\"https://files.jameslittle.me/images/2021-desk-post/IMG_5823.jpeg\"></Image><p>It took me a week to troubleshoot the issues I had with using my Sony camera as a full-time webcam. I realized pretty quickly that I needed to get a dummy battery, so I had to swap camera batteries between meetings until that came in the mail. I also had issues with my camera overheating, until I removed the SD card from the camera, which seemed to stop it from shutting off mid-meeting. I know that using my camera in this way has a high potential of burning the sensor out, so I try to turn it off at the end of my workday.</p><Image src=\"https://files.jameslittle.me/images/2021-desk-post/Zoom Screenshot.png\"></Image><p>I also recently got a <a href=\"https://www.bhphotovideo.com/c/product/1476390-REG/nanlite_12_2003_compac_24_dimmable_5600k.html\">Nanlite Compac</a> that I've mounted on my desk as a key light. It blinds me during meetings, but the extra light helps people see me and lets me use a slower aperture (F5.6 instead of F2), which helps the camera's autofocus not hunt as much. If you're going to use a &quot;real camera&quot; as a webcam like this, keep it in autofocus—you might get some hunting, but it's better than irreperably dropping out of focus when you lean back.</p><h3>Headphones</h3><Figure layout=\"wide-half-left\"><Image src=\"https://files.jameslittle.me/images/2021-desk-post/DSC05406.jpg\"></Image></Figure><p>The last part of my AV setup is audio out. Connected to the CalDigit is a <a href=\"https://www.schiit.com/products/modi-1\">Schiit Modi</a> audio interface that stacks on top of the <a href=\"https://www.schiit.com/products/magni-1\">Schiit Magni</a> headphone amp. They go into a pair of <a href=\"https://drop.com/buy/massdrop-x-sennheiser-hd-58x-jubilee-headphones\">Massdrop/Sennheiser HD 58X Jubilee headphones</a>. It sounds great -- I like to listen to Apple Music's lossless tier and pretend I hear a difference.</p><p>When I want to listen to audio out loud, I play it through a <a href=\"https://www.apple.com/homepod-mini/\">HomePod Mini</a> that sits on my desk.</p><h2>Miscellaneous</h2><p>A few more things I keep full-time on my desk:</p><ul><li>A triple-charger that charges my phone via Magsafe, my Apple Watch via its proprietary magnet/Qi charger, and my Airpods case via a normal Qi charger. It's turned my desk from a space where my devices drain battery to a place where they can gain battery; it's been nice to not have to keep a bunch of stray cables around (or even worse, go into the other room to charge anything).</li><li>A succulent plant that's been dying for the past two years</li><li>Some pens and sticky notes that I rarely use</li><li>A stainless steel ball that spins on a flat base. I spin this thing when I'm bored or thinking - it's a little fidget tool.</li><li>A coaster, to cover up the rings on my desk from when I didn't use a coaster</li><li>A lamp with a LifX bulb in it. Usually warm white, I probably switch it to a fun color about once per month. I use Homekit automations to control it every single day, though</li></ul><h2>Conclusion</h2><p>I've tried prioritizing so that my setup makes me do my best work. It should encourage me to work on the stuff that brings me the most joy, and should reduce the friction to get into and maintain a flow state. I think I'm mostly there? I have the tools I need (and then some) to do work for my job and spend some time on personal projects afterwards, and I have enough gadgets and toys that I can keep myself engaged and drawn in. I've turned my space into one that's really good for video communication, so my experience with computers is less solitary. I'm happy with how I've set things up in 2021, and I'm excited to see how the space will evolve in the year to come.</p></article>",
            "url": "https://jameslittle.me/blog/2021/2021-work-setup",
            "title": "2021 End-Of-Year Work Setup",
            "summary": "It's where I work, it's where I relax, it's where I plan my life, it's where I talk to friends, it's where I enjoy music, it's where I read the news, it's where I spend most of the hours of the day...",
            "date_modified": "2021-12-29T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2021/25-at-25",
            "content_html": "<article><p>I turned 25 this week. Here are 25 things I've learned in the past 25 years.</p><ol><li>Good things often don't just happen, you have to work to make them happen. Doing this work is okay, expected, and honestly more rewarding than letting things &quot;just happen&quot; to you.</li><li>On the corollary, when things <em>do</em> &quot;just happen&quot;, they're often bad things -- the world tends toward entropy. Expect this, accept this, and brush it off -- don't let the world drive you crazy.</li><li>Small, consistent effort is the secret to getting things done. The dopamine won't be there to reward you along the way, so it's tough to get going. Working on something a little bit each day will look smaller than you hope in the short-term, but will end up bigger than you think in the long term.</li><li>Focus more on improving local community. Trying to reason about global community is overwhelming since global community is often uncontrollable by any individual.</li><li>Local community can often happen on the internet, too!</li><li>Invest in the things that make you happy, even if those investments aren't prudent.</li><li>Time is a resource. If you're a budgeting kind of person, think about how you'd budget your time. It might be worth it to track your time to make sure you're spending it where you think you are (or where you want to be spending it)—it's been worth it for me.</li><li>Invest in things that make your work take less time. Reducing friction makes things exponentially easier and reduces mental hurdles needed to do those things.</li><li>Kindness always takes work and is usually worth it.</li><li>Writing is amazing. It helps you think through problems. It acts as a time capsule for ideas or observations. It lets you offload things from your brain. Write more—you never have to do anything with it if you don't want to, but it'll still be valuable.</li><li>From <a href=\"https://justinmcelroy.wordpress.com/2013/11/08/what-it-has-taken-me-33-years-to-learn/\">Justin</a>: It feels really good to correct people when they say something wrong, but unless it's going to cause meaningful problems down the line, don't do it. You don't want to be, like, the guy who jumps in and tells someone that they messed up. Take a breath, acknowledge the wrongness internally, and let them keep going.</li><li>If you're born with or otherwise acquire advantages or privileges, that's not your opportunity to sit back and enjoy a smoother life. Take that extra time, extra energy, extra mental space and learn about the struggles that other people in the world (or in your local community, see above) are facing. Work on making the world better for them. In other words, the plane is depressurized and your oxygen mask is already on -- that's your opportunity to help the people next to you with theirs.</li><li>Dig up curiosity within yourself. The world is made up of systems: systems of technology, systems of people, etc. To whatever extent you can, find the drive to figure out how those systems work. It'll help you figure out what's happening and how you can best make change.</li><li>Networking (IP, DNS, HTTP, the wifi in your house) is one of those systems that you should figure out.</li><li>You don't have to be an expert to try something new out.</li><li>You don't have to always aim to improve at a skill in order to be happy doing it.</li><li>Code is written for people, and software meant to be changed. Don't get too tricky when simpler code works just fine.</li><li>When you <em>do</em> get tricky with your code, use that trickiness to make it harder for people to make changes that will break things down the line.</li><li>Sometimes when you don't think you know much about a subject, you really just don't know the right language to talk about that subject with others. Find the language first and see how much your understanding grows.</li><li>When building a project, the code is fun, but the marketing, onboarding experience, and design is more important if you want it to be used by other people.</li><li>If given the opportunity, develop environments where people can be more creative than usual.</li><li>Your own enthusiasm is contagious. If you're hyped about something, you can get other people hyped about it too.</li><li>The details are more intricate than you expect, and they need more attention than you'll expect to need to give them.</li><li>It's hard to be an authority in a field that focuses on one topic, because there will be so many other people looking into that same thing from different angles. Instead, work to be an authority on the combination of two different things. The combinatoric possibilities are much more vast, and there will be a lot more room in that field for you to explore, grow, and learn.</li><li>Don't carry too much stuff in a backpack at one time. (The exception: when backpacking)</li></ol></article>",
            "url": "https://jameslittle.me/blog/2021/25-at-25",
            "title": "25 at 25",
            "summary": "I turned 25 this week. Here are 25 things I've learned in the past 25 years.",
            "date_modified": "2021-11-26T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2021/stork-and-modularity",
            "content_html": "<article><p>I've been working on making <a href=\"https://stork-search.net\">Stork</a> a more modular project. Stork has a lot of code in it; to make it more readable, I've been putting that code in different files. With Rust, every file is a different module (for the most part), so this winds up with lots of stacked modules. Rust also lets you only reference modules absolutely (starting from the crate) or relatively (by ascending up the module stack and then descending down), so my imports were getting kind of unwieldy.</p><pre data-language=\"rust\">super::super::super::config::file::SRTSubtitleFormat // :(\n</pre><p>This has been mostly manageable, but recently, <a href=\"https://healeycodes.com\">Andrew</a> wanted to compile Stork on an environment (x86 Amazon Linux 2) for which my release process doesn't create a binary. I spun up an ec2 instance, tried to compile Stork, and was disappointed to find that it doesn't compile - the new &quot;download a web page and index it&quot; feature relies on OpenSSL, which the Rust installation was having trouble finding. <Footnote>This seems like a bug? I'll have to go back and reproduce it and file it later, probably on <a href=\"https://github.com/sfackler/rust-openssl\">this repo</a>.</Footnote> As a workaround, I wanted to see if there was a way to conditionally compile out that code. Andrew wouldn't be able to download web pages and index them, but that's better than not being able to run Stork after all.</p><p>In a Rust crate, you can use <a href=\"https://doc.rust-lang.org/cargo/reference/features.html\">features</a> to mark code as optional. When the feature is on, it will be compiled into the binary. When the feature is off, the compiler will act as if that code isn't there. You can also mark crates as installed only when a feature is enabled, so my original plan was to put that web-page-downloading feature (and the crates it depended on) behind a feature and try compiling Stork with that feature disabled.</p><p>While I was poking at my features, I wanted to change how I approached the modularity of the project. There are some aspects of the code, like a &quot;common&quot; module which contains things like constants, type aliases, and some shared models, that I wanted to extract into its own crate. In fact, there are several modules in the root of Stork that could be their own crate. For example, Stork supports parsing and searching indexes from old versions of Stork, which means the WASM binary has to include a separate deserialization schema that 99%<Footnote>Or 100%! I don't have the analytics to determine, though none of the indexes I've seen through the analytics I _do_have are using the old format.</Footnote> of people don't use. It'd be nice to offer a smaller WASM binary that doesn't include that code, if folks know they won't need it. So this weekend, I got up close and personal with my Stork repo to split out my WASM bridge models, my v2 index, my v3 index, and my config models into their own crates.</p><p>As usual, the compiler admonished me repeatedly. <Footnote>This isn't a bad thing! Compiler admonition is much better than runtime failure; that's one of the reasons I like writing Rust so much.</Footnote> I was referencing things across modules in a way that wasn't allowed -- or at least, that I shouldn't repeat -- across crates. I updated nearly every import in the project. It felt like I was finally making some of the sketchier parts of the codebase clearer, which felt nice. Along the way, I cleaned up my custom error implementations with the <a href=\"https://github.com/dtolnay/thiserror\"><code>thiserror</code></a> crate, which was really satisfying. And getting to a place where I had easily understandable crates with small public interfaces all interacting with each other made me look forward to building on top of those crates in the future. <Footnote>In Rust, &quot;Crate&quot; is its own visibility level. Now that there are more crate boundaries in the project, I can be a lot more granular about what symbols are visible, so I can make more symbols private (or make symbols private more easily) than I could before. That makes me more likely to write documentation for my public interfaces (or even care about them when I previously hadn't), since those public interfaces are now more logical and meaningful than they were before.</Footnote></p><p>And yet, this project seemed futile for a good portion of it. Stork still doesn't compile, so there's more work to do. None of the work seemed all that meaningful -- I wasn't adding new features, I was hacking on my import statements. Most of all, though, was the combinatorial explosion of compilable versions of Stork. Now, in my CI, I'll have to test 5 crates' test suites with different sets of features enabled and disabled, and I believe I'll have to define all those combinations manually. My local development (rust-analyzer) seems to have broken itself after looking at code that doesn't exist in the compiled output for so long. I've added more boilerplate in the form of crate definitions. I'm worried that I've made my life more complex to make the public interfaces of my code less so. I can see the benefit of enforcing better public interfaces immediately, but I won't really feel the pain of the combinatorial explosion until later, so right now, I'm biased towards thinking this was a good idea when it might actually be a bad one that will only sneak up on me after a few months.</p><p>I want to keep hacking on this, mostly because I'm <em>so close</em> and because it'd be nice to be able to give Andrew a working binary. But I think I realized that spending a weekend on my build configurations doesn't spark as much joy as building something new.</p></article>",
            "url": "https://jameslittle.me/blog/2021/stork-and-modularity",
            "title": "Stork and Modularity",
            "summary": "Splitting code into crates, the benefits of small public interface, and a combinatorial explosion.",
            "date_modified": "2021-09-19T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2021/stork-analytics",
            "content_html": "<article><p>I wrote a little Node application that downloads all the Cloudfront logs that <a href=\"https://stork-search.net\">Stork</a> generates, and sticks the data in a SQLite database. I stuck a Dockerfile in front of that application. Then, I added another directory that has a Dockerfile pointing to <a href=\"https://datasette.io\">Datasette</a>. Now my project is a monorepo that contains multiple services.</p><p>A monorepo? Services? Complexity has skyrocketed.</p><p>I started up an EC2 box. I installed Docker on it, and I set up <code>docker-compose</code> and a crontab so that this box does two things: it serves my Datasette instance on port 80, and it runs the Node application on a cron job. Now, every 6 hours, my Datasette instance updates with the latest usage stats for Stork, and I can use the Datasette web instance from anywhere.</p><p>I can write SQL queries and get stats about the HTTP requests coming into the Stork CDN. It's my own little data warehouse! Mission accomplished.</p><hr><p>I think <a href=\"https://observablehq.com\">Observable</a> released <a href=\"https://observablehq.com/@observablehq/plot\">Plot</a> about one day after I got Datasette working. Suddenly, I wanted—nay, needed—to do some fancy visualization with my Stork data so I can really <em>see</em> the stats.</p><p>I tweaked my Datasette Dockerfile to install a <a href=\"https://github.com/simonw/datasette-auth-tokens\">token-based authentication plugin</a>. Now my data is secure, but accessible via an API. I wrote an Observable notebook that fetches the most recent usage data and plots it. Now I have a usage dashboard with a graph showing how many hits <code>stork.js</code> got per day this year.</p><p>It's got a rolling average!</p><Figure caption=\"I don't think I'm ready to share the y-axis here, sorry.\"><Image src=\"https://files.jameslittle.me/images/stork-stats.png\"></Image></Figure><p>I reckon this is the most stable thing I've launched in a prod environment. This feels like the deployment with the smallest bundle of hacks I've ever created. I spent shockingly little time installing software on the EC2 box, which is a task I've easily burned weeks on before. Moreover, I can run each service independently in production or on my personal computer. I'm happy with this because I don't think I'll have to keep worrying about it forever.</p><p>Acknowledgements: <a href=\"https://twitter.com/terinjokes\">Terin</a> helped reaffirm that I was using Docker correctly. Thanks, Terin!</p></article>",
            "url": "https://jameslittle.me/blog/2021/stork-analytics",
            "title": "Building Internal Analytics for Stork",
            "summary": "A Docker love letter? An admission that I'm bad at dev-ops? Maybe I just did something I want to brag about. This is that brag.",
            "date_modified": "2021-06-02T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2021/subscription-pricing",
            "content_html": "<article><p>Apple released subscription plans for in-app purchases a few years ago, which opened the door for a lot of new and existing apps to move their payment plan to a subscription model. This happened to be roughly the same time in my life as when I started wanting to (and being able to) pay for more of the software I used, and, over a relatively short timespan, the subscription dam burst. A few bucks per year for 1Password. A lot of bucks per year for Adobe's stuff. All the streaming services have their own subscription. Then came Patreon. Online courses. According to my spreadsheet, I spend lots of money each month!</p><p>I am young enough (and my parents shielded me enough) to have not thought about subscriptions in everyday life, like the cable plan or the cellphone plan my family subscribed to. I grew up thinking about spending money as a finite set of one-off transactions. Buy a thing, get a thing. But the subscription dam burst for me with App Store in-app subscriptions, and I started thinking about what it means to spend money on a recurring basis to get (and then, eventually, maintain) access to something, or to support people who build things, or both. It seems like a lot!</p><p>But is it? Context is important, and if you're comparing subscriptions to one-off purchases, then the subscription will always be more expensive. But my theory is that <em>more things in life fit under the subscription model than the one-time purchase model than we'd care to admit.</em> When I buy a car, I'm required to also buy an $XX/month subscription for gas and insurance if I want to use the thing. If I decide to lease a car, I've effectively turned it into a subscription model. I spend a good amount of money each week on groceries. Every utilities bill is a subscription payment.</p><p>But the car purchase itself is a subscription, since that car isn't going to last forever. If you get a new one, you've effectively signed yourself up for a different kind of subscription: one with longer periodicity, higher per-period costs, and sometimes less predictability. If you've ever bought something to replace something else, the amount you spent back in the day can be amortized over the life of the thing you're replacing, and you've modeled your spending as a subscription payment (and the clock starts over for the new thing you just bought). If you replace your car every 10 years, you're effectively signing up for a $208/mo subscription service, assuming you buy a $25k car each time. The only way you get out of it is if you don't replace the things you buy, you either stay content with the things you have for the rest of your life, you barter really well, or you don't replace the things you own. Suddenly, spending $5 each month to make sure the Technology Connections guy can keep doing his thing doesn't seem so ridiculous anymore. The sticker shock just isn't there when it's compared against the car thing.</p><p>I guess this came up because I saw someone on the internet railing against subscription software. I've watched subscriptions bring out pettiness in people on the internet for the past ten-plus years, and as I've realized that I can blur my vision and see <em>everything</em> as a subscription, I'm less and less empathetic to people who declare that they &quot;have a fundamental aversion to subscription pricing.&quot;</p></article>",
            "url": "https://jameslittle.me/blog/2021/subscription-pricing",
            "title": "The Sneaky Ubiquitousness of Subscription Pricing",
            "summary": "Every purchase is subscription pricing if you squint hard enough. This isn't a bad thing.",
            "date_modified": "2021-05-25T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2021/stork-in-the-news",
            "content_html": "<article><p>I've been lucky enough to be able to talk about <a href=\"https://stork-search.net\">Stork Search</a> in two different settings this month!</p><h2>console.dev</h2><p>The first was a <a href=\"https://console.dev/qa/stork-search-james-little/\">developer interview as part of console.dev's Q&amp;A series</a>. In this series, founders David and Max expand on entries in their <a href=\"https://console.dev\">developer tools newsletter</a> by talking to the people who build these tools to learn more about the project and about how they work. It was a really fun interview, and I got to talk about my desk setup a bit and nerd out about the tools I use, which was fun!</p><h2>fission.codes</h2><p>The second was a <a href=\"https://vimeo.com/529898007\">presentation as part of fission.codes' tech talk series</a>. In this hour-long talk, I presented Stork to an audience of mostly the <a href=\"https://fission.codes\">fission.codes</a> team, but also to a few guests! I talked about the backstory of the project, about the niche which Stork occupies and the problem it's trying to solve, and I got to deep-dive into the architecture of the code. I ended up putting the slides and a text version of the talk <a href=\"https://jameslittle.me/talks/stork\">on a new section of this site</a>.</p><hr><p>I'm really grateful for both opportunities to talk about Stork! Thanks to David (from console.dev) and Boris (from Fission) for reaching out and giving me a place to speak.</p></article>",
            "url": "https://jameslittle.me/blog/2021/stork-in-the-news",
            "title": "Stork in the News",
            "summary": "Sharing press coverage of Stork from the past month.",
            "date_modified": "2021-03-28T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2020/one-year-of-stork",
            "content_html": "<article><p>Just before the holidays, I launched version 1.0.0 of <a href=\"https://stork-search.net/\">Stork</a>, the web search library I’ve been building for just over a year. Stork is a tool for building dynamic, responsive, and native full-text search interfaces—usually only possible with a SaaS product or a web server—that can be added to static, serverless web pages. It’s free, open-source, and build-system-agnostic. It’s one of the tools I wish I had when I was starting to build websites.</p><Note><p>If you want to try a demo or read the documentation, visit Stork’s website: <a href=\"https://stork-search.net\">https://stork-search.net</a>.</p></Note><p>Working on Stork has changed how I’ve interacted with the web development community. Stork is only successful if the people who use it find it useful and delightful. Over the past few months, I’ve pushed myself outside my comfort zone and connected with other web developers to ensure that that’s the case. For the first time, I’ve gotten to talk with people from across the internet who seemed excited about the tool I’ve built, and I’ve been able to contribute back to the web development community, an online community of creatives that has shaped how I use technology.</p><p>I built Stork because I thought it should exist, but in fact, <strong>Stork was a project I didn’t know I was capable of building until I had already built it.</strong> A year ago, I had no experience with full-text search, with Rust or Webassembly—the two technologies that power Stork—or with open-source contribution. In this essay, I want to describe how I approached the first year of building Stork. First, I’ll describe why I built it; then, I’ll expound on full-text search and what a serverless search plugin brings to the web; finally, I’ll tell you why I’m excited for the next few years of Stork.</p><h2>The Web is an Organism that We All Built Together</h2><p>It’s hard to remember which came first: the idea for Stork, or my desire to build something (anything!) for the web development community. Web development is the corner of programming where I feel most comfortable, since it seems to foster an environment of unbounded creativity—inherent to the internet, it seems, is the idea of giving something to others. <strong>The languages that power the web are powerful, but verbose, and this verbosity means that developers are strongly encouraged to use community-built tools to speed up their development.</strong> Therefore, the creativity sparked by the web platform is not just first-order creativity—in the content that gets published—but also second-order creativity—in the <a href=\"https://www.arp242.net/open-source.html\">open source</a> tools that are used to publish and enhance that content. The presence, ubiquity, and power of these tools makes the web development experience a communal one instead of a solo endeavor.</p><p>Without the web, I wouldn’t be a programmer, and without the tools and resources that the web development community has built, I wouldn’t have started building websites. Regrettably, I’ve found it easy to forget about the community members who have built the tools that got me into web development. It’s only recently (mostly by following folks on Twitter) that I’ve discovered the humanity and individuality of the people who build the tools I use. That discovery fueled me to create something, and eventually, that something became Stork. When I started building Stork, I wanted to create something useful to give back to the web development community, from whom I had taken so much.</p><h2>Finding an Unfilled Niche</h2><p>Working on a college newspaper and watching the editors struggle to dig old articles out of the digital archives turned me onto the idea of a search experience optimized for specific domains. The web technologies available to replace the newspaper’s custom Google search were either too expensive or too finicky, and I realized I had stumbled across a niche that seemingly didn’t have anything filling it: easy-configuration full-text web search. I theorized that sticking to client-side technologies would simplify the integration experience drastically—I didn’t want to set up another search server, so I assumed other people wouldn’t either. I then theorized that client-side full-text search didn’t exist because the technology that could power it was very new.</p><p>Around that time, Rust’s WebAssembly support had been drastically improved and increasingly publicized. I had recently listened to <a href=\"https://www.relay.fm/radar/141\">Marco Arment discuss his implementation of full-text search on an episode of Under the Radar</a>, and Chris Coyier had recently published his <a href=\"https://serverless.css-tricks.com/\">Serverless</a> microsite. I was lost in wondering what a Jamstack search experience would entail. I realized that with the right algorithm, I could build a tool in Rust that generated a heavily-compressed search index where the results were precomputed for any valid query, and where I could use the speed of WebAssembly to parse and search through that index on the client. It was around this time that I started talking about the idea (not yet named Stork) at work and online, and met some friends—<a href=\"https://twitter.com/noopkat\">Suz Hinton</a>, <a href=\"https://twitter.com/matthiasendler\">Matthias Endler</a>, and <a href=\"https://twitter.com/healeycodes\">Andrew Healey</a>—who were excited about the project, graciously let me bounce ideas off of them, and encouraged me to share my work more widely (to them and to others I’ve talked to: I’m incredibly grateful for your feedback, support, and friendship).</p><h2>Search is a Hard Problem to Solve</h2><p>The first few months of Stork, I spent time proving out the idea, but in transitioning Stork from a tech demo into a product, I had to find a suitable balance between building algorithmic excellency and building an intuitive experience. <strong>I strongly believe that in this stage of Stork’s development the product must be polished before the algorithm is.</strong> The speed and the search results can be “good enough” in the first years of the product, but if Stork gives off a bad first impression, then nobody will use it. This is the philosophy I brought to the first year of Stork’s development.</p><p>The early versions of Stork used <a href=\"https://tom.preston-werner.com/2010/08/23/readme-driven-development.html\">Readme-driven development</a> almost religiously. Before the search algorithm worked, I was building a Javascript API, building server infrastructure, and building the first search interface theme. <strong>I wrote Stork’s user-facing documentation, then made sure I wasn’t building a tool more complicated than the documentation allowed.</strong> I became obsessed with concisely describing the two steps of working with Stork: first building an index from a corpus, then loading that index into a webpage using the Stork Javascript library.</p><p>Splitting up those two steps into user-visible actions is endemic to Stork’s operation. Stork tries to front-load as much of the work as possible, precomputing search results so that the client only performs a few lookups to build its results. Today, Stork’s indexer parses documents and builds a hash-table that maps words and prefixes to their character offsets within a document. The client—the WebAssembly executable—looks up each word in the user’s query, combines the results, and uses those offsets to display excerpts from the document, giving users context for each of their search results (by necessity, each Stork index must carry the full text of every document in the index). This strategy creates search indexes that are unfortunately large, but I maintain that the resulting experience makes the tradeoff worth it.</p><p>Any full-text search algorithm involves two main pieces of functionality. First, the entire set of entries must be filtered to only those that match the search query. Second, the remaining entries must be sorted so that the most “relevant” entries are listed first. Stork’s prefix map handles the filtering, and I’ve built a rudimentary sorting algorithm that takes word-closeness, presence of queries in titles, and exact-vs-partial-match details into account—it works well in the inputs I’ve tried. Improving this ordering algorithm has taken a significant portion of Stork’s development, and most of the code I’ve deleted and rewritten has come in the form of overarching improvements to the relevance ordering. I’ve learned about <a href=\"https://en.wikipedia.org/wiki/Stop_word\">stop words</a>—words like “the,” “it,” and “and” which must be indexed but heavily devalued, about how to correctly normalize both corpus input and search input so that Power⎵ matches power, about <a href=\"https://en.wikipedia.org/wiki/Stemming\">stemming</a> algorithms that let me match tries in an index to try in a query, and I’ve watched search results improve as I incorporate each of these enhancements into Stork’s search algorithm.</p><h2>Stork’s Next Steps</h2><p>As I said before, I released the latest version of Stork as version 1.0.0. With this, I hope to signal Stork’s prime-time readiness and present Stork as a feature-rich project that’s ready for wider scrutiny. This is a Stork that I’m proud of and that I want to contribute to the web development community.</p><p>In encountering different open-source projects, I’ve tried to pluck the features I feel have helped me the most. The landing page contains a demo, the current version number, and working sample code (three things that an unfortunate number of landing pages seem to omit). I’ve published the project’s roadmap, and I encourage feature requests and bug reports on Github. Most importantly, though, I’m writing about Stork with a human touch, with the hope that the people who interact with the project can better recognize that there’s a coder behind the code.</p><p>I’m actively looking for people to try Stork in their own site and give me feedback. It might not be there yet (though it might be for you!), but I believe that Stork can be an easy, flexible solution to anyone who wants to implement web search, and I’m excited to put in the work to make it so. That said, Stork is far from complete. My scratchpad is pages long <Footnote>Features I’m excited to build include: 1) mutating index files from the command line instead of creating a new one, 2) fetching documents from the web, and 3) using web workers so that the WASM computation doesn’t crush the main thread.</Footnote>, and I plan to continue building features and enhancements for a while. As I see it, Stork will be useful until it’s irrelevant, and will be relevant until people stop building Jamstack-based sites. I’m also banking on the community to help me: feature requests, bug reports, and other communication has already helped Stork become a better tool, and I’m excited to see what further contributions the community will add to Stork.</p><p>If you’re interested in learning more about Stork, here are some links:</p><ul><li>The project’s page, including a demo: <a href=\"https://stork-search.net\">https://stork-search.net</a></li><li>The project on Github: <a href=\"https://github.com/jameslittle230/stork\">https://github.com/jameslittle230/stork</a></li></ul><p><em>Thanks to <a href=\"https://twitter.com/lehrjulian\">Julian Lehr</a> and <a href=\"https://twitter.com/bgdotjpg\">Ben Guo</a> for reviewing early versions of this post.</em></p></article>",
            "url": "https://jameslittle.me/blog/2020/one-year-of-stork",
            "title": "Stork Turns One: Building a search tool for static sites with Rust and WebAssembly",
            "summary": "Stork, my web search side project, is launching publicly after one year of development. This post describes the goals I took on while building it and how I got from idea to release.",
            "date_modified": "2020-12-27T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2020/len-laster",
            "content_html": "<article><p>Papa, I think, always wanted me to be a writer. Technical briefings probably aren't quite what he had in mind, but even still, I think he'd be excited to know that so much of my job today consists of putting pen to paper and writing a project proposal or an incident postmortem, since above all else, the things I write these days are driven by a story. It was my grandfather who taught me how to tell a story: how to weave together characters, conflict, and humor above all else to bring out a response from anyone who would listen.</p><p>I don't know how much of his aptitude for storytelling he brought to his professional world. <a href=\"https://www.ccgfuneralhome.com/obit/dr.-leonard-laster\">Dr. Leonard Laster</a> had already retired by the time I was born, so while others knew him as Dr. Laster the Gastroenterologist or Dr. Laster the researcher or Dr. Laster the Presidential Adviser, I knew him as Papa, who would tell me stories of my kidneys when I didn’t want to drink my orange juice, stories complete with the dramatic groans and whines my kidneys surely were making, sound effects which would leave me cackling at the breakfast table. Papa would weave tall tales to keep me entertained, like the story of two supermarket owners, Mr. Stop and Mr. Shop, who inevitably clashed over what in the store actually constituted merchandise (I would always have to interject to say that no, the checkout counter wasn't for sale!) Goofball stories like that were his way of <em>being</em> a grandfather and sharing love with the youngest members of his family. Throughout the childhoods of four different grandchildren, Papa was responsible for more laughter in his Cape Cod house than the rest of us combined: the increasing ridiculousness of the stories he told brought his family together and built a home filled with love, warmth, and comfort.</p><Image src=\"https://files.jameslittle.me/images/wohouse.jpg\"></Image><p>The roots of a good story are the words that make it up, and for Papa, words were a way to connect with the people he loved. When I was young, Papa encouraged my budding interest in word games, which I think provided both of us an extraordinary opportunity to grow close. We tried to be crossword editors together, channeling our inner Will Shortzes and discovering simultaneously how difficult the job of a puzzler actually was. Later, we both fell headfirst into the New Yorker's Cartoon Caption Contest: I would try to describe the scene, and Papa would pluck out the humor from my description then submit the caption (in his name only, since New Yorker rules stipulated I wasn't old enough to enter). One year, after summer had ended and I had gone back to Brookline, we wrote most of a book together, alternating chapters that we'd send to each other by email. In all these projects—word games, puns, and storytelling alike—he took my abundant, overexcited energy and guided it towards quality and polish. In a gentle way, he managed to keep my interest and, above all, encourage me to just write, no matter what I was writing. The stories he told and the stories he helped me put together brought me into his world of using narrative to captivate an audience, keep them entertained throughout a piece, and introduce people to a new point of view.</p><p>As I grew older, even after I convinced myself I shouldn't become a novelist (or puzzle editor, or cartoonist), Papa never put the importance and social power of writing to rest. The ancient dictionary in the great room was the great argument-settler of dinnertime conversation, as Papa would lead the family down etymology and spelling conversation holes. Words, for him, were a tool for learning about the world and teaching others. In late 2007, as the Eel Pond Drawbridge in <a href=\"https://en.wikipedia.org/wiki/Woods_Hole,_Massachusetts\">Woods Hole</a> was getting reconstructed, Papa wanted me to create a picture book that described how drawbridges work, highlighting the technological advancements going into the new bridge. My grandfather was no stranger to using words to guide others: his scientific publications changed the world’s understanding of the human body, he wrote a book for young doctors to describe different paths they could take with their medical degree, and he was a frequent columnist in the Falmouth Enterprise. More recently, after Papa had started slowing down, I'll admit to having rifled through the archived papers he kept in the basement, and found some inter-office memos from when he was a chancellor at UMass Medical Center. I shouldn't have snooped, but as I did, I found the writings of a passionate leader who believed in the power of institutions and the greatness that could come out of collaboration. It was his words—sharp and witty, carefully chosen, and flush with precision and power—that led others and guided those he met, worked with, and loved on their best course.</p><Image src=\"https://files.jameslittle.me/images/swope.jpg\"></Image><p>My grandfather was a gift to all of us. I miss him tremendously, and the change that has come to our family will be felt forever. But, scientist as he is, Papa would be the first to say that there is a bit of him in all of us, genetic or otherwise. I see his leadership in my uncle, his vision for building lasting institutions in my aunt, and his empathy in my mother. All his grandkids inherited his wry sense of humor—there truly hasn't been a funnier Passover seder in all of Cape Cod. All twenty-three years I had with him were a gift, and as I look forward to summers in Woods Hole, to the family he built (who I love so much), and to my passion for using writing to learn and to teach, I'm grateful that the gifts he gave us will stay with me for the rest of my life.</p></article>",
            "url": "https://jameslittle.me/blog/2020/len-laster",
            "title": "On my Grandfather, Dr. Leonard Laster",
            "summary": "1928–2020",
            "date_modified": "2020-10-31T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2020/cmd-line-applications-appkit",
            "content_html": "<article><p>I've been writing a <a href=\"/webpic\">Mac app</a> that runs command-line applications under the hood. This app presents itself as a nice wrapper around a few different image-processing command-line applications: you could download my app and &quot;free yourself&quot; from having to manage these command-line image processors yourself.</p><p>The idea of building a GUI around a command-line app is well-trodden territory: Git clients are a common example.<Footnote>Of course, we can go one layer deeper. Not only do they make &quot;GUIs around a command-line app,&quot; people also make and use &quot;Terminal-based GUIs around a command-line app&quot;, like <a href=\"https://github.com/rgburke/grv\">GRV</a>.</Footnote> Often, though, these applications assume that you already have the command-line tool installed, and I didn't want to make that assumption with the app I'm building. I wanted some way to embed the command line application in my Mac app so that you could download the app on a fresh computer, on any supported version of MacOS, and be able to use it.</p><p>I ultimately figured out how, and will tell you soon, but first...</p><h2>You likely don't want to do this</h2><p>This isn't a typical way of going about running other dependent programs from your program. If you were building a GUI around Git, for example, you'd likely want to include <a href=\"https://libgit2.org/\">libgit2</a>—a C library for interacting with Git—as a code dependency, rather than bundling the <code>git</code> command-line executable with your app. If you're processing JPEG images, you'd want to <a href=\"https://github.com/libjpeg-turbo/libjpeg-turbo/blob/master/BUILDING.md#build-procedure\">build and use the libjpeg C API</a> instead of building libjpeg and including the <a href=\"https://linux.die.net/man/1/jpegtran\"><code>jpegtran</code> executable</a>. If you have a library for interacting with the software, you get more natural code hooks for directly interacting with the service, rather than trying to go through a frontend designed for humans. <Footnote>It's not entirely natural to think of a command-line application as a frontend designed for humans, especially since there are so many tools (like Bash scripts) that programmatically interact with command-line interfaces.</Footnote> This library will often give you more power and control. It'll be faster, since you won't be spinning up a new process just to run some code. You'll be more easily able to distribute the library, and the library will often work on more targets. <Footnote>A term which here means &quot;the set of computers, processors, and/or operating systems you want to compile your code to work with.&quot;</Footnote></p><p>You might not want to work with the whole software library, though, especially if it's designed for more complex use cases than yours. You might be sure you can do everything you want to do from the command-line interface. You might not care about the portability concerns, or the additional time and computing overhead that starting a new process will take. Or there might not be a library for you to work with at all: the command-line interface might be the only way you can interact with the program. If that sounds like your scenario, then carry on.</p><h2>But if you're sure, here's how you do it:</h2><p>I downloaded the program (in my case, <code>jpegtran</code>) using <a href=\"https://brew.sh\">Homebrew</a>. This installed the compiled executable file (or <em>binary</em>) to my machine. (Alternatively, you could compile jpegtran yourself.) I then located the freshly-installed binary on my disk:</p><pre>$ which jpegtran\n/usr/local/bin/jpegtran\n</pre><p>Ultimately, I want to embed this file in my own <em>application bundle</em> <Footnote>In macOS, GUI applications aren't just single executable files. Instead, they're bundles: specially handled directories that contain assets, config files, and the executable.</Footnote> and call into it from my code.</p><p>I copied the file into my project folder in a special (but arbitrary) directory I had already made. I called it <code>lib</code>, for &quot;Libraries.&quot;</p><pre>$ cp /usr/local/bin/jpegtran ~/project/Project/lib/\n</pre><p>You'll see a <code>lib</code> folder appear in your Xcode sidebar.</p><p>Now, you need to tell Xcode that it should include the <code>lib</code> directory in the application bundle. In Xcode, go to your project settings and click on your application target. In the top navigation bar, you'll see a &quot;Build Phases&quot; tab, and once you select that tab, you'll see &quot;Copy Bundle Resources&quot; as one of the build phases. Expand that build phase, and drag and drop the <code>lib</code> directory from Finder into the list of bundle resources.</p><Image src=\"https://files.jameslittle.me/images/xc1.png\"></Image><p>Now, build and run the app and open the application bundle in the Finder. <Footnote>Not sure how? Right click on the icon in the dock, and select &quot;Options → Show in Finder&quot;. Right click on the application in the Finder window, hold down option, and select &quot;Show Package Contents&quot;. The folder you'll find yourself in holds the contents of the application bundle: welcome!</Footnote> You'll be able to see your freshly minted <code>lib</code> directory (under <code>Contents/Resources</code>).</p><p>Now you can run the command-line app from your code. When you build (and later distribute) your application, the application bundle will have the binary in its <code>lib</code> directory, and you can use Foundation's <a href=\"https://developer.apple.com/documentation/foundation/process\">Process API</a> to run it with all the command-line flags you want:</p><pre data-language=\"swift\">let process = Process()\nlet stdOutPipe = Pipe()\n\nprocess.executableURL = URL(\n    fileURLWithPath: &quot;Contents/Resources/lib/jpegtran&quot;,\n    isDirectory: false,\n    relativeTo:  NSRunningApplication.current.bundleURL\n)\n\nprocess.arguments = [&quot;-progressive&quot;, &quot;-verbose&quot;, &quot;-optimize&quot;, &quot;~/hey.jpeg&quot;]\n\ndo {\n    process.standardOutput = stdOutPipe\n\n    try process.run()\n\n    stdOutPipe.fileHandleForReading.readabilityHandler = { fileHandle in\n        print(fileHandle.availableData)\n\n    }\n} catch {\n    fatalError(&quot;Something went wrong!&quot;)\n}\n</pre><p>Unfortunately, though, this probably won't work.</p><p>It's highly likely that you're not working with a standalone binary; instead, your binary probably depends on one or more <strong>dynamic libraries</strong>. Dynamic libraries (sometimes called <em>dylibs</em>) are libraries of code that are installed on the computer in a shared library space, and linked with the executable at runtime. <Footnote>Dynamic libraries are contrasted with static libraries, which are &quot;burned into&quot; the executable during compilation. When I was talking about libgit2 and libjpeg in the introduction, I was talking about including those static libraries in your application and calling into that code.</Footnote> If your binary depends on any dynamic libraries, those dylibs are not guaranteed to be included on the user's system. <Footnote>Even if they were, a sandboxed Mac application can't access files (including dynamic libraries) outside the application bundle unless given specific permission. If you try to call a dylib from within the sandbox, it'll fail.</Footnote> We have to first include those dylibs in the application bundle, then <em>manually change the command-line app's binary</em> so it will tell the linker to look for those dylibs in the application bundle instead of in the shared library space.</p><h3>Wait, what?</h3><p>Binaries contains a list of the names and locations of each dylib that binary depends upon. Those names are set during compilation, so they're accurate for whatever system they're compiled for. <Footnote>When you install an application from a .pkg file using <a href=\"https://en.wikipedia.org/wiki/Installer_(macOS)\">Installer</a>, one of the things the installer script might be doing is installing new dylibs into your shared library space.</Footnote> You can list the dylibs a given application depends on using <code>otool</code>:</p><pre data-language=\"bash\">$ otool -L /usr/local/bin/jpegtran\n/usr/local/bin/jpegtran:\n\t/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1281.0.0)\n</pre><p>This shows that <code>jpegtran</code> relies on one dylib, and that dylib is located at <code>/usr/lib/libSystem.B.dylib</code>. Your goal for the rest of the article is to patch the <code>jpegtran</code> binary so that instead of pointing in <code>/usr/lib</code> (a location outside the app sandbox), it instead points to the application bundle, where we'll install a copy of the dylib so we can distribute it with our app.</p><h3>Alright</h3><p>To include the dylib in our application bundle, we create a new directory next to <code>lib</code> (I called it <code>frameworks</code>), and copy the dylib into that directory:</p><pre data-language=\"bash\">$ cp /usr/lib/libSystem.B.dylib ~/project/Project/frameworks/\n</pre><p>Create a new &quot;Copy Files&quot; build phase and set the destination to &quot;Frameworks&quot;. Drag your newly-copied dylib from the Finder to the list of files in Xcode. When you build your project, you should see the dylib in <code>Contents/Frameworks</code>.</p><Image src=\"https://files.jameslittle.me/images/xc2.png\"></Image><p>By installing them into the <code>Frameworks</code> directory, Xcode knows to embed the framework in the application target in such a way that the linker can reference it.</p><p>Now that your dylibs will be included (and linkable) whenever you build and distribute your application, you need to point your executable towards the dylib's new home.</p><p>Usually, the executable points to an absolute file path. We don't know where the application bundle will live on disk, so we can't use an absolute path here. Fortunately, <code>dyld</code> (the macOS linker) recognizes some keywords that let us build up a relative path instead. For example, <code>@executable_path</code> will be replaced by the path of the binary that requested that dylib. With the <code>install_name_tool</code> utility, we can change the executable so that it points to a dylib path relative to <code>@executable_path</code>. Since the structure of the application binary will always be the same, we can be confident that our relative paths will always resolve.</p><p>As a reminder, here are the relevant files within the application bundle:</p><pre>Project.app\n├─ Contents\n   ├─ Resources\n   │  ├─ lib\n   │     ├─ jpegtran\n   ├─ Frameworks\n      ├─ libSystem.B.dylib\n</pre><p>We use this command to reconfigure <code>jpegtran</code> to point to a new location for <code>libSystem.B.dylib</code>:</p><pre data-language=\"bash\">$ cd project/Project/lib\n$ sudo install_name_tool \\\n   -change &quot;/usr/lib/libSystem.B.dylib&quot; \\\n   &quot;@executable_path/../../Frameworks/libSystem.B.dylib \\\n   jpegtran\n</pre><p>Now, the copy of <code>jpegtran</code> in the <code>lib</code> directory will point to the copy of <code>libSystem.B.dylib</code> in the <code>frameworks</code> directory, and because everything lives in the application bundle, running the command-line application from within your app code won't hit any sandbox-related file access issues, and it won't hit any &quot;missing dynamic library&quot; issues. If the Swift code to run <code>jpegtran</code> didn't work before, it should work now.</p><p>This process can be a little tedious. If your binary relies on multiple dylibs, you will have to go through this process for each one. Sometimes, you might encounter a dylib that depends on another dylib. You can use the same tools (<code>otool</code> and <code>install_name_tool</code>) to reconfigure the dylib, just as you did to reconfigure the executable.</p><h2>That was exhausting.</h2><p>Yes.</p><h2>Resources</h2><ul><li><a href=\"https://stackoverflow.com/a/15106738/3841018\">@bdash on StackOverflow, answering &quot;How to set dyld_library_path in Xcode&quot;</a></li><li><a href=\"https://wincent.com/wiki/@executable_path,_@load_path_and_@rpath\">&quot;@executable path, @load path and @rpath&quot; by Greg Hurrell (@wincent)</a></li><li><a href=\"https://www.mikeash.com/pyblog/friday-qa-2009-11-06-linking-and-install-names.html\">Mike Ash: &quot;Linking and Install Names&quot;</a></li></ul></article>",
            "url": "https://jameslittle.me/blog/2020/cmd-line-applications-appkit",
            "title": "Running Command-Line Applications from a Mac App",
            "summary": "You probably don't want to embed a command-line application in your Mac app. But if you do, I'll guide you along the dynamic library and Xcode configuration journey.",
            "date_modified": "2020-04-22T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2020/about-the-guestbook",
            "content_html": "<article><p>Adding the <a href=\"/guestbook\">guestbook</a> to my site was really fun: it was the kind of project that seemed easy at first, but had a lot of complexity under the hood. I kept thinking I was done, then realizing there was some edge case I hadn't quite thought of. I wanted to write down some of those edge cases and subtle challenges I faced, mostly to show that features that seem simple on the outset might actually take a while to put together.</p><p>Some notes: during the course of development, I decided to optimize for <em>cost</em> first, then <em>speed</em>, then <em>safety</em>, then <em>availability</em> in that order.</p><ul><li>The guestbook is two parts: a form and a list of entries. I need to store those entries somewhere, and I need to be able to fetch them on demand. I could have used a MySQL database and used a server-side scripting language to build the page. That would probably take a VPS, which would cost $5/month. Instead, I built up a REST API using AWS Lambda as the application layer and S3 as the storage layer.</li><li>Given that model, I had to figure out how I would read from and write to my S3 data store. I decided that creating a new entry would write a new file to S3 and getting all the entries would loop through all the files in the bucket, get their contents, and output a list. (This also means that reading is likely more expensive than writing, since it uses O(n) S3 reads for every GET request.)</li><li>I wanted to make sure nobody spams my API. I'm using AWS' API Gateway <a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-api-usage-plans.html\">Usage Plans</a>. Ultimately I want to make sure I'm letting as many people legitimately make API requests as possible without overrunning my Lambda budget or my S3 budget.</li><li>I needed to figure out which endpoints my API had. People need to read data and write data, so that sounds like a POST and a GET.<ul><li>Will people need to read data in different ways, like getting individual entries?</li><li>Will people need to perform other actions, like message deletion?</li><li>The answer to both of these questions might be &quot;yes&quot; in the future, but for now I'm passing on both of them.</li></ul></li><li>I had to define what a valid request looks like, for both my POST endpoint and my GET endpoint.</li><li>I had to figure out how to validate the requests, and write up a system for doing so. As part of this, I had to figure out which input parameters are required and which are optional, and for each parameter, what &quot;validity&quot; looks like.</li><li>I had to figure out what my validation errors look like. What happens if you don't include a required param? What happens if you include an unexpected param? I decided that since I was controlling the frontend and backend, I could be as strict as I wanted and throw errors judiciously (instead of maybe dropping unknown fields).</li><li>I had to define what a valid response looks like, for both endpoints, in the success and failure cases.</li><li>I had to set up CORS headers in API Gateway.</li><li>I also had to make sure that Lambda errors were translating into API Gateway 400s correctly.</li><li>I had to write tests for my API to make sure all the inputs I thought of got to their respective outputs.</li><li>Eventually I also ended up setting up a QA database and writing a little hook so I could avoid writing to my prod database while I'm developing. This ended up being nice in theory but unused in practice.</li><li>This is all user-submitted data. How do I get notified that a new entry has been submitted, and do I even want those notifications? How can I make sure nothing gross is being put up on my page? How do I block users that are abusing the guestbook? (These are all unsolved problems... for now.)</li></ul><p>The frontend was, shockingly, even more challenging.</p><ul><li>I had to figure out how often the client would fetch the data (i.e. hit the GET endpoint). I assumed once per page load, but wondered if more was necessary.</li><li>I then wondered if that assumption even true? Instead, I could cache data on page loads and show you cached data instead of running the lambda function on every page load. (Ultimately I didn't do this.)</li><li>I had to figure out my UI state. I realized there were two independent state machines: the success/loading/failure when fetching the guestbook entries, and the success/loading/failure when submitting the form.</li><li>I had to define UI for each of those states.</li><li>I wanted a message at the top of the list that said something like &quot;3 messages.&quot; I had to make sure &quot;messages&quot; wasn't pluralized when there was one message in the list.</li><li>I had to figure out what happens when you submit the form. I considered adding client-side validation, but decided that would be too complex for a feature I had already built into the backend.</li><li>If you submit the form successfully, the form values should disappear, and we should show a success message.</li><li>I had to decide whether or not to re-fetch the data if the form was submitted successfully. Ultimately I decided it shouldn't; it should &quot;fake it&quot; by adding the entry to the local store of entry objects. This would reduce the number of GET calls, and would be a valid tradeoff based on what the writer cares about: they don't need to see all the entries that were added between page load and form submission, they just want to see their entry added as part of the greater list.</li><li>If the form doesn't validate, display the error and keep all existing data present.</li><li>I put a lot of thought into dates here, both how they're stored and how they're displayed. Ultimately, I decided that the Lambda function would determine the creation timestamp of a given entry, which meant the value <em>wasn't</em> present on the submitted object when the client created it and sent it to the server. However, the date field has to have something in it when it gets appended to the displayed list of entries. Ultimately I ended up appending a &quot;date&quot; value to the submitted object before adding it to the local store; this date value is likely different from what the server records, but only by a factor of milliseconds.</li><li>I still have to figure out if date display works in other timezones besides PST.</li><li>I had to determine when to display relative dates (&quot;two days ago&quot;) vs. absolute dates (2020-03-14). I wanted to provide a hook so that if you want to know the absolute date, you could see it even if the relative date was visible.</li></ul><p>I was very surprised that &quot;the page should record entries from this form and display them on the bottom of the page&quot; turned into a week-long project in which I had to grapple with all these challenges!</p><p>If you haven't yet, go <a href=\"/guestbook\">write something in the guestbook</a>, if for no other reason than so I don't look silly.</p></article>",
            "url": "https://jameslittle.me/blog/2020/about-the-guestbook",
            "title": "About the Guestbook",
            "summary": "It's interesting to think that a feature that seems so intuitively simple can have so many challenges, questions, and choices once you start building it. Here are the ones I faced while building /guestbook.",
            "date_modified": "2020-03-16T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2020/css-grid-wish",
            "content_html": "<article><p>I redesigned my website! It uses Eleventy now and some bits should be better but a lot of the bits remain the same.</p><p>I cared a lot about the page layout for this version—the layout of the last redesign was kind of awful. I wanted to align things on a grid, and I knew that other people had found that CSS Grid was becoming a better and better layout tool, so I wanted to see if I could put my entire website in a grid and make the layout fall into different grid areas.</p><p>I knew I wanted a central column for text, and I wanted that central column to be nicely sized so your eyes don't get tired tracking across super-long lines of text. I also wanted some elements to be able to break out of that central column into a wider, but still centered column. You can likely see the intended result on the <a href=\"/portfolio\">portfolio page</a>, but here's a diagram:</p><Figure><Image src=\"https://files.jameslittle.me/images/layout-2.png\" alt=\"All elements fit into a central column, except for one which is wider.\"></Image></Figure><p>With an indended HTML structure of:</p><pre data-language=\"html\">&lt;div class=&quot;grid&quot;&gt;\n  &lt;header&gt;...&lt;/header&gt;\n  &lt;main&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;div class=&quot;breakout&quot;&gt;...&lt;/div&gt;\n    &lt;p&gt;...&lt;/p&gt;\n  &lt;/main&gt;\n&lt;/div&gt;\n</pre><p>Turns out this is impossible, as far as I can tell. Only direct child elements are grid sub-items, and if I have (as displayed here) a <code>&lt;div&gt;</code> inside a <code>&lt;main&gt;</code> inside a <code>display: grid</code> element, the <code>&lt;main&gt;</code> will be the grid item (and will be able to conform itself to a given grid area), but the contents inside don't have access to that grid.</p><p>If I change the <code>&lt;main&gt;</code> to be the grid, then every element inside it will try to fit inside a whole grid area; there's no concept of laying out elements in a normal page flow if they're all in the same grid area and then modifying one element to exist in a superset of that area.</p><p>I hacked around it with a carefully calculated negative left margin, and I get why CSS grid works the way it does (in essence, it's not the right tool for the job I want to do), but there still seems to be room for CSS layout to improve here. I've watched CSS authors get less reliant on hacks to encode certain types of layouts, but I'm still not sure we've found the right abstraction for someone who wants to make a layout like mine.</p></article>",
            "url": "https://jameslittle.me/blog/2020/css-grid-wish",
            "title": "Something I wish CSS Grid did, but it doesn't",
            "summary": "Can I, just, like, complain for a second? Thanks.",
            "date_modified": "2020-02-01T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2020/money-stuff",
            "content_html": "<article><Note><p>I wrote this for my brother. Money decisions are intensely personal, and if you aren't my brother and you don't agree with what I've written here, note that your financial situation is likely different and you should do different things accordingly.</p></Note><p>When you're not in school anymore, at some point you will get a job and start making money. Good for you! You're employed!</p><p>Once you're employed, your first goal should be making sure you're spending, on average, less than you make. The unit of time doesn't really matter, but since so much of the world works on a monthly cadence (bills, rent, Netflix subscriptions, etc.), my thought process centers around spending less each month than I make in an average month. When you spend less than you make, then congratulations! You can start saving!</p><Note><p>It takes some people a lot of time just to get to the employed + saving part, and that's ignoring very common issues like debt. I don't mean to imply that getting to this point is necessarily easy, just that much of the advice I'm going to give explains what you should do once you get there. If you have debt, you'll want to employ a different strategy.</p></Note><p>Generally you start out with a single bank account, usually a <strong>Checking Account</strong> or a <strong>Savings Account</strong> at some bank. Once you're making a profit every month, you'll see the numbers in those accounts go up at a regular cadence, and you'll find that you're storing a sizable chunk of cash in that account. Unfortunately, a checking or savings account is generally a bad place to store sizable chunks of cash. To understand why, we have to explore the spectrum of <strong>liquidity</strong> and <strong>yield</strong>.</p><p><strong>Liquidity</strong> is, roughly speaking, the ease with which something turns into cash. Cash is the Most Liquid Thing because cash very easily turns into cash. Money in your savings account is very liquid because it too very easily turns into cash at an ATM. A <strong>bond</strong> is not very liquid. When you buy a bond, you give the government money and they promise to give you more money after a certain amount of time, like two years. When the government has your money, it's very difficult to turn into cash: the government won't give you the money back until the two years is up. But they give you more money, which is sort of like a thank-you for letting them borrow your money for two years. Comparing a bond to money in your savings account is a good example of a general investing rule:</p><p><strong>The more liquid an asset is, the lower yield you'll be able to get from it.</strong></p><p>When your money is in a savings account, you get a 0.03% APY (<strong>Annual Percentage Yield</strong>)[^1]: your money will grow 0.03% year over year. That is shockingly little, but you can access it immediately, whenever you want. If you put your money into a CD (a <strong>Certificate of Deposit</strong>, which is kind of like a bond), you get a 2.15% APY, but you don't see that money again until two years later.[^2] If you buy a house, you can get a very large return on investment, but in order to turn your house into cash, you have to sell the house, which is a chore.</p><p>Real estate complicates the General Investing Rule by introducing the concept of <strong>risk</strong>. You don't always get the same return on investment when you buy a house because buying a house is very risky: land value rises and falls drastically and (in some senses) arbitrarily. On the other hand, putting your money in a bond is not risky: once the bond's time is up, you'll get your original money + the APY unless the government has gone bust, at which point you'll have bigger problems. This introduces the second general investing rule:</p><p><strong>The riskier it is to put your money somewhere, the more reward you have the potential of getting, but the higher the likelihood is that you'll lose it all.</strong></p><p>In 2019, annual inflation was 2.29%. $100 on December 31, 2019 is worth 2.29% <strong>less</strong> than that same $100 was worth on January 1, 2019. Careful readers might notice that that inflation rate is more than the APY of the CD listed above, and is <strong>much</strong> more than the APY of the savings account. This means that if you put all your money in a savings account or a CD, that money is slowly losing its value each year. Bummer! In order to ensure that your money isn't slowly losing value, you want to invest in things that have a higher APY than inflation: generally, people shoot for at least a 3% APY for their investments. Based on the two rules of investing, you can deduce that there are two ways to get a high APY: either invest in very non-liquid things, or invest in high-risk things. You could get a 10-year CD and get an APY of 2.3% (still low-risk but incredibly low-liquidity), but instead we're going to talk about investing in the stock market, which introduces some risk but means you can very easily get over the inflation hump and start having your money make money.</p><p>Your first entry point into the stock market should be through <em>tax-advantaged brokerage accounts</em>, which is a fancy way of saying retirement accounts (so you get taxed less) that other people manage (so you don't stress out about stocks). Why do you get taxed less when you put your money in retirement accounts? The American government wants you to be set to retire. They want to make sure you're putting enough money away so that when you <em>do</em> retire, you're not using too many public resources to fund your retirement. To get you to save your own money for retirement they give you incentives, which come in the form of lower taxes.</p><p>Generally, when you make money, you have to give the government some of it. That's regardless of how you make that money, so when you get a paycheck you pay taxes on that, and if you use some of your paycheck to buy some shares of a company and you make money, you also pay taxes on that. For those of you keeping score at home, that means you get taxed twice, once for each income event. The government has set up two types of investment buckets where, if you play by the rules and don't take money out until you retire, you only get taxed once. Those two buckets are:</p><ul><li>a <strong>Roth IRA</strong>, in which you pay taxes on income but don't pay taxes on investment profits, and</li><li>a <strong>401k</strong>, in which you (typically, but not always) pay taxes on investment profits but not on the portion of your income that goes into it.</li></ul><Note><p>You're only allowed to have one of each, and they both come with federal contribution limits. As of 2020, you're only allowed to put $6,000/year in a Roth IRA, for example, and you're not allowed to contribute to a Roth IRA at all if you make more than $135,000 annually. The rules are more complex than that, and a 401k has other rules.</p></Note><p>I called both of them &quot;buckets&quot; because they're not types of investments themselves; rather, they hold the various investments you can have. Having a 401k doesn't mean you've invested money in any particular thing. You could buy two thousand shares of Snapchat (really Snap Inc.) and have that be your entire 401k if you were crazy. Generally, though, you don't want to be the one picking which companies you invest in. Instead, you want to pay smart finance people money to pick the stocks, because they're going to be better than you at picking them.</p><p>The smart finance people have set up <strong>index funds</strong>, which are big slurries of different stocks that the finance people manage while skimming a small amount of profits off the top. There are tons of different index funds: there are some that invest equally in each of the top 500 American companies. There are some that invest in specialized markets, like foreign shipping companies. There are some that dynamically switch from stocks to bonds over time, such that the fund is a high risk and high reward one today, but in 2065 will be low risk and low reward (which is generally how you want to manage a retirement portfolio). The index funds you invest in are kind of a personal choice, though that choice mostly depends on your willingness to take on risk.</p><h2>What You Should Do</h2><p>You should create a Personal Investor account with Vanguard, which is a company that does two things: they offer different types of brokerage accounts (the 401k and the Roth IRA are examples of types of brokerage accounts), and they manage a suite of index funds. Vanguard is a trustworthy company that people really like; it also makes your life simple to choose them because you can go to one website and manage all your investments there.</p><p>By convention, people generally set up a Roth IRA on their own, and let their employer set up a 401k for them. Once you've created your account with Vanguard, you should open a Roth IRA with them. Over the course of the year, you should transfer money into your Roth IRA; you don't want to transfer it all and buy all your index funds at once, because you don't know if this is a particularly expensive time for the stock market; instead, you want to contribute and invest a bit, regularly, throughout the year.</p><p>As you transfer money into that account, you'll be able to invest that money in different index funds. I've invested in index funds like:</p><ul><li><a href=\"https://investor.vanguard.com/etf/profile/VOO\">VOO</a>, a set of stocks in the S&amp;P 500 index. VOO has effectively had an 11.66% APY over the past 5 years.</li><li><a href=\"https://investor.vanguard.com/mutual-funds/profile/VLXVX\">VLXVX</a>, a fund that adjusts its stocks over time with a target retirement date of 2065. It is a very new fund but effectively had a 24% APY over the past 1 year.</li><li><a href=\"https://investor.vanguard.com/mutual-funds/profile/VTWAX\">VTWAX</a>, which is some fancy global fund with a low expense ratio: they skim relatively little off the top. This fund is also new, and has had an effective 17.54% APY over the past year.</li></ul><p>At roughly the same time you're setting up a Roth IRA, you'll want to set up an emergency fund. You want an emergency fund to be high liquidity (so you can get to the cash easily) and low risk (so you don't wake up in an emergency to find it gone), which will mean that it has a low APY, even below inflation. People tend to think of this as a price they're paying to have access to their emergency fund. You want your emergency fund to hold roughly 3-6 months of expenses. You can also fill this up gradually, similarly to how you contribute to your Roth IRA over the course of the year. I have my emergency fund at Ally Bank, which is an internet-only bank which offers a savings account with a roughly 1.7% APY (it fluctuates, but has historically lived around there). Internet banks have some tradeoffs (I can only withdraw money 6 times per year without incurring fees), but the increased yield is worth it; I've never withdrawn from my emergency fund.</p><p>You'll be able to hang out with a Roth IRA and an emergency fund for a while, just contributing to both of them and watching those numbers go up. You should keep some money in your checking account to pay for day-to-day expenses, but you'll want to make sure that your IRA and emergency funds are eventually holding the bulk of your cash.</p><p>I'm at the point where even if I contribute the maximum amount to my Roth IRA, I still want to invest more money so I'm not hoarding cash in my checking account. For this, I opened another, generic brokerage account with Vanguard: I still invest my money in their index funds, but it's not a special retirement tax account, it's just a normal account: I pay my income tax before the money goes into it, and my capital gains tax when money comes out. I also have a 401k from work, and I have a Robinhood account with a few hundred dollars in it so I can pretend like I'm one of the smart finance people and pick my own stocks. But my financial life isn't any more complicated than that, and my money is doing as much work for me right now as I feel comfortable with it doing.</p><p>More Resources:</p><ul><li><a href=\"https://i.imgur.com/lSoUQr2.png\">The Reddit Personal Finance Flowchart</a></li><li><a href=\"https://twitter.com/bdc/status/1204468710645235713\">A Twitter thread outlining a still-very-basic but also more-complex Vanguard index fund guide</a></li></ul><p>[^1]: Source: <a href=\"https://media.bac-assets.com/DigitalDeposit_CA_CA_Bay_Area.pdf\">https://media.bac-assets.com/DigitalDeposit_CA_CA_Bay_Area.pdf</a> [^2]: Source: <a href=\"https://www.salliemae.com/banking/certificates-of-deposit/\">https://www.salliemae.com/banking/certificates-of-deposit/</a></p></article>",
            "url": "https://jameslittle.me/blog/2020/money-stuff",
            "title": "Money Stuff",
            "summary": "An overarching description of my financial setup, preceded by some of the concepts you need to know about in order to understand what you should do with your money. Meant to help someone go from basic saving to investing.",
            "date_modified": "2020-01-16T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2020/splitt-postmortem",
            "content_html": "<article><p>I was working on a project called <a href=\"https://splitt.xyz\">Splitt</a>, which was meant to be an interface for figuring out, for a given group of people, who owes money to whom. One person could pay for something, add it to Splitt, and then over time Splitt would reconcile the transactions between the people in the group. My girlfriend and I had a complicated spreadsheet going to do this, and I wanted to build something that did the same thing with a nicer interface and a better data model. I eventually wanted to publicize it, give it a nagware business model like Sublime Text, and have it become a Successful Side Project™. Today, I'm killing it and wanted to write about why.</p><p>I thought it would be a good way to get practice <em>making something</em>: particularly something that has a robust UI, a solid REST API that could be consumed by the two clients (Vue on web, and a never-really-finished iOS app), and a good backend data structure. I thought of the idea in the summer (in the shower, where all good ideas originate) and started working on it a few days later. It'd be a good idea, I remember thinking, to get some backend practice in before <a href=\"https://jameslittle.me/blog/2019/next\">starting at Stripe</a>.</p><p>I never really checked to see if there was anything like this out there already. When I had something working and showed it to my coworkers, they were very curious about how it compared to <a href=\"https://www.splitwise.com/\">Splitwise</a>, an app I hadn't heard of but probably should have. Turns out Splitwise is basically everything I had wanted Splitt to become—if I had seen Splitt's roadmap through, there wouldn't have been much functional difference between it and Splitwise.</p><p>I then had the choice to either keep Splitt going and rethink its roadmap or shut it down and just use Splitwise instead. My girlfriend and I chose to create a Splitwise group (we liked their UI and their functional iOS app better), so Splitt is officially no more. I will eventually be setting Splitt to read-only, and have set the the three repositories (Laravel backend, Vue frontend, and iOS app) to public, so you can examine and criticize my work:</p><ul><li><a href=\"https://github.com/jameslittle230/splitt-back\">https://github.com/jameslittle230/splitt-back</a></li><li><a href=\"https://github.com/jameslittle230/splitt-vue-front\">https://github.com/jameslittle230/splitt-vue-front</a></li><li><a href=\"https://github.com/jameslittle230/splitt-ios\">https://github.com/jameslittle230/splitt-ios</a></li></ul><p>Ultimately, the only real lesson I can think of here is &quot;make sure you know the competition and the landscape before starting out on a project.&quot; If I had known Splitwise already existed, I could have spent more time either working on ways Splitt could have been different, or I could have spent more time working on something else entirely.</p><p>I also learned how <em>difficult</em> software can be! I had come up with a lot of infrastructure-y ideas for Splitt, like blue-green deploys, an admin dashboard, and a Stripe integration. But it turned out that building the actual software had to come first by necessity, and that took up enough time that I never got around to all the &quot;bonus&quot; stuff.</p><p>I'm still working on side projects—more word coming soon on what I've been doing lately.</p></article>",
            "url": "https://jameslittle.me/blog/2020/splitt-postmortem",
            "title": "A Bummer of a Postmortem",
            "summary": "I recently sunsetted a project because the thing already existed. If I never wrote about it, it would be lost to the endless void of time, since I never talked about it anywhere else.",
            "date_modified": "2020-01-03T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2019/nas",
            "content_html": "<article><p>I got, as a gift a few years back, a <a href=\"https://www.synology.com/en-us/products/DS418j\">Synology DiskStation DS418j</a> along with three Western Digital 8TB Red hard drives. This allowed me to put together a NAS (Network-Attached Storage): a relatively low-powered storage server that lives on my local network. Now that I've moved into an apartment, I've been able to tweak my setup to something relatively enjoyable.</p><Figure caption=\"I dusted it to take the photo, and the photo _still_ looks like trash.\"><Image src=\"https://files.jameslittle.me/images/synology.jpg\"></Image></Figure><h2>Prelude: Internet in General</h2><p>I live in an area that's serviced by <a href=\"https://sonic.com\">Sonic</a>, and I'm lucky to get Gigabit internet (roughly 1,000 Mb/s upload and download) coming into my home. That goes into a small, nondescript 8-port Cisco switch that I borrowed a long time ago. That switch goes to a <a href=\"https://en.wikipedia.org/wiki/Google_Wifi\">Google Wifi unit</a>: I have two Google Wifis in the apartment, one which acts as a hub and one which acts as a repeater. The switch also sends wires to the Synology, a Raspberry Pi, and my computer.</p><p>If I had the choice to re-do things, I wouldn't get the Google Wifi unit for multiple reasons, the first of which being that the system doesn't work with Synology's DDNS: either the port-forwarding gets blocked, or the DNS resolution does, I haven't figured out which. The eventual goal is to switch to a more configurable system—I hear <a href=\"https://unifi-network.ui.com\">Ubiquiti</a> makes a good system, but I haven't done enough research to say I'll commit one way or another.</p><h2>The Synology</h2><p>I primarily use the Synology as file storage. When you set up the operating system, you can decide how you want the RAID setup to work. I think the best option (and also the default option) is SHR, which is similar to RAID 5 but works with different size disks.<Footnote>Raid 5 stores unique data on n-1 disks, then sets the last disk to be the XOR of all the previous disks. SHR does the same thing, but makes sure the XOR'd disk is of the biggest volume (so the XOR data will fit).</Footnote> I set up a single volume and have multiple directories in that volume's root.</p><p>The first directory in root is called &quot;Files&quot;, and it stores files. I keep all the documents I created for school, papers I found online, fonts, things like a PDF of my lease, backups of my photo libraries (I'll get back to that), etc. Anything I don't think I'll need immediately gets offloaded from my computer hard drive to the Files directory: this keeps my computer's boot drive nicely not-full. I was also able to stop using Dropbox by storing my documents on my Synology: I was only really using my Synology as a way of getting to my files from elsewhere; Synology's remote login has eliminated this. Files is generally uncomplicated, I mostly use it as a loosely-sorted write-only archive of my digital life.</p><p>Importantly, I <em>don't</em> store things like movies in my &quot;Files&quot; directory. I set up my Synology as a Plex server, and so my media lives elsewhere. Plex is neat: I can store video and audio files on the Synology, install a server application on the Synology, and then install client applications elsewhere (like the web, or on an Apple TV) and I can stream media from my Plex to that client application. I used <a href=\"https://9to5mac.com/2019/07/26/set-up-plex-synology-nas/\">a tutorial from 9to5Mac</a> to set up Plex on my Synology. Importantly, which either this tutorial leaves out or I overlooked, the Plex installer will set up a new Plex user and will expect media to live in <code>/Homes/Plex</code>, <Footnote>Plex has a very opinionated way it wants you to organize your media library. I don't have the time to get into it now, but needless to say it not only matters where the media lives but also how it's curated.</Footnote> which in turn assumes that each user on the Synology has a home directory. It's a bit weird for each user to have a home directory <em>and</em> have them all using the Files directory in the volume's root, but here we are.</p><p>I also use the Synology as a Time Machine destination for my computer and my girlfriend's computer. I used <a href=\"https://nascompares.com/2019/04/08/how-to-back-up-your-mac-to-synology-nas-with-time-machine/\">another tutorial</a> for getting that working, and I've just been able to set it and forget it -- it's apparently (if my reported Time Machine stats are accurate) been chugging along for months now just fine. Importantly, though, that means I have two more users and two more directories in root: &quot;JL Time Machine&quot; for my backups and &quot;MT Time Machine&quot; for my girlfriend's.</p><p>All these files are backed up to Amazon Glacier via a twice-per-week cron job, set up through the Glacier Backup package. Glacier <a href=\"https://medium.com/@karppinen/how-i-ended-up-paying-150-for-a-single-60gb-download-from-amazon-glacier-6cb77b288c3e\">might not be the best tool to back up all my files</a>, but it is not meant to be my primary offsite backup forever: I'll probably opt to start giving Backblaze some money soon and also back stuff up to their B2 service. For now, though, this Glacier setup <em>really</em> gives me peace-of-mind. I've lost some videos of my childhood to the unending churn of hard drives, and I like knowing that once I put something on my Synology I'll have it ~forever, unless I really try hard to delete it or someone nukes us-east-1 or something.</p><p>I mostly access the Synology through the web interface (for browsing files, changing settings, and installing packages), through the command line for running scripts, or through <a href=\"https://www.panic.com/transmit/\">Transmit</a>, which is a gorgeous file transfer application made by Panic. That means I need to make the web interface ports and the SSH ports available—SSH is used both for logging into the box in the Terminal and for SFTP, which is how I connect Transmit to the Synology. <Footnote> I also have whatever ports are used for the Time Machine file sharing system: maybe AFP, or maybe Bonjour? I have to reiterate how much it was a &quot;set it up and never think about it again&quot; kind of operation—I'm not really sure what it's doing.</Footnote> I have QuickConnect set up, which works fine: it proxies your Synology to the outside world via proprietary magic. I also had Synology's DDNS set up, which worked much better than QuickConnect but broke when I started using Google Wifi as my router, since Google Wifi and DDNS don't work together. I don't enable SSH on the standard port, but it's moot anyway since there isn't a public IP address that resolves to the Synology.</p><h2>An Interlude: The Pi-Hole</h2><p>A month ago I bought a Raspberry Pi 3 model B on Amazon just for fun. Eventually I turned it into a Pi-hole: a DNS server that drops hostnames that are known advertising hosts, effectively giving myself a network-wide ad blocker. I used <a href=\"https://www.reddit.com/r/pihole/comments/bppug1/introducing_the/\">a blocklist I found on Reddit</a> and it's been outstanding -- I can't recommend it enough. I've gotten to the point where I go to work and am bummed that the internet there is jankier because of all the ads. I get cool stats. I save bandwidth. What's not to love?</p><p>(Admittedly, this isn't related to my NAS [other than the fact that they're the only two devices on my network that have reserved IPs] but it <em>is</em> part of my networking setup, and I felt like it was important to include.)</p><h2>Conclusion?</h2><p>I think my Synology setup is very good. I like the file storage. I like that I can throw big <a href=\"https://youtube-dl.org\"><code>youtube-dl</code></a> jobs on it and it'll just churn and download everything in the background. I like that I can keep every single photo I take in RAW format until the end of time -- I don't have to be judicial with how I spend my data. I like that when my hard drive is getting full, I can just drag and drop a lot of files to the little box that lives under my desk and my hard drive will be no longer full.</p><p>It's good. It's worth it, I'd say.</p></article>",
            "url": "https://jameslittle.me/blog/2019/nas",
            "title": "How I Use my Network-Attached Storage",
            "summary": "What do I use my Synology DS418j for? How did I get it all set up? What's running on it right now? Let's talk about Plex, Time Machine, file hoarding, and (for some reason) the Pi-Hole.",
            "date_modified": "2019-10-21T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2019/debugging-cors",
            "content_html": "<article><p>I've been thinking (<a href=\"/blog/2019/cors\">and writing</a>) about CORS recently because there's (as of this writing) a CORS error on the <a href=\"https://bowdoinorient.com\">Bowdoin Orient's site</a>. The stylesheets for loading the Orient's fonts are coming up with a CORS error in the Firefox console, while the Chrome console shows CORS errors for both the stylesheet and the font files.</p><p>I thought the solution would be fairly easy, but a quick diagnostic showed that it's a little more complicated than originally expected. As I write this, I'm not sure what needs to be changed to fix the issue, but I'm going to try to outline my thought process while I debug it.</p><Note title=\"Post-debug update\"><p>This ended up being more of an AWS configuration issue than a CORS issue, but I'm still leaving it up to show how I got here. CORS bugs require that you know about your specific HTTP server, about browser security policies, and about different ways HTTP requests can be made; throughout this process, I had to tap into all of those.</p></Note><ul><li><p>Is this really even a problem? The site looks fine to me—the fonts are showing up fine.</p></li><li><p>My computer has the Orient fonts downloaded locally, so maybe the browser is finding the fonts there. I should check on a different computer.</p></li><li><p>I checked on my girlfriend's computer. The CORS errors are still showing up in her browser's console, but the fonts look pretty much fine, except for one: Chronicle, font weight 700, not italic.</p><ul><li>Interestingly enough, 700/italic, 600/regular, and 900/regular are all available. It just seems to be that one weight/style combo.</li><li>Also interestingly, <em>every</em> font coming from the CDN is showing CORS errors in the console, but every font except that one combo looks... totally fine.</li><li>I wish I could deprioritize the bug given that it's not breaking all the fonts, but the Chronicle 700 font is used as the article headline on the <a href=\"https://developer.wordpress.org/themes/template-files-section/post-template-files/#single-php\">single.php page</a> which is arguably the most viewed part of the website.</li></ul></li><li><p>The browsers are complaining that there isn't an <code>Access-Control-Allow-Origin</code> header on the response, so let's figure out why not.</p></li><li><p><em>Some investigation later</em></p></li><li><p>The response headers in the network tag don't have an <code>Access-Control-Allow-Origin</code> header</p></li><li><p>When I copy the Curl request, I don't see the headers either:</p><pre data-language=\"bash\">$ curl 'https://font-cdn.bowdoinorient.co/files/orient-fonts.css' \\\n-H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:68.0) Gecko/20100101 Firefox/68.0' \\\n-H 'Accept: text/css,*/*;q=0.1' -H 'Accept-Language: en-US,en;q=0.5' --compressed \\\n-H 'DNT: 1' -H 'Connection: keep-alive' -H 'Referer: https://bowdoinorient.com/' \\\n-H 'Pragma: no-cache' -H 'Cache-Control: no-cache' -I\n\nHTTP/2 200\ncontent-type: text/css\ncontent-length: 17214\nlast-modified: Thu, 28 Feb 2019 00:37:37 GMT\naccept-ranges: bytes\nserver: AmazonS3\ndate: Sun, 25 Aug 2019 00:09:55 GMT\netag: {idk maybe this should be censored}\nage: 21541\nx-cache: Hit from cloudfront\nvia: 1.1 275c261effb3ee5f39bd3dd96f438f26.cloudfront.net (CloudFront)\nx-amz-cf-pop: SFO5-C3\nx-amz-cf-id: {maybe this should be censored too??}\n</pre></li><li><p>I checked AWS and the bucket <em>should</em> have CORS set up on it. The <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/cors-troubleshooting.html\">CORS troubleshooting documentation</a><Footnote>My goodness this page was a slog to find. And it's not even that helpful.</Footnote> says there need to be certain criteria met before the CORS-related headers are included in the response.</p></li><li><p>I wonder what happens when only use an <code>Origin</code> header.</p><pre data-language=\"bash\">$ curl 'https://font-cdn.bowdoinorient.co/files/orient-fonts.css' \\\n-H 'Origin: https://bowdoinorient.com' -I\n\nHTTP/2 200\ncontent-type: text/css\ncontent-length: 17214\ndate: Sat, 24 Aug 2019 03:54:06 GMT\naccess-control-allow-origin: https://bowdoinorient.com\naccess-control-allow-methods: GET\naccess-control-max-age: 3000\naccess-control-allow-credentials: true\nlast-modified: Thu, 28 Feb 2019 00:37:37 GMT\netag: {censored}\naccept-ranges: bytes\nserver: AmazonS3\nx-cache: RefreshHit from cloudfront\nvia: 1.1 100e7eca600d702a8613a94cb0899fe9.cloudfront.net (CloudFront)\nx-amz-cf-pop: SFO5-C3\nx-amz-cf-id: {censored}\n</pre></li><li><p>Nice. So CORS is set up properly.</p></li><li><p>When I use a <code>Referer</code> header instead of an <code>Origin</code> header in the request above, it still works. So something in the full request is causing the CORS headers to drop.</p></li><li><p>I sequentially added each header in a new CURL request. It wasn't any of the headers, it was the <code>--compressed</code> flag.</p></li><li><p>I looked up what the <code>--compressed</code> flag does for CURL:</p><blockquote><p><strong><code>--compressed</code></strong> (HTTP) Request a compressed response using one of the algorithms curl supports, and save the uncompressed document. If this option is used and the server sends an unsupported encoding, curl will report an error.</p><p>— <code>man curl | grep compressed</code></p></blockquote></li><li><p>I thought my S3 configuration was wrong, but maybe it's my Cloudfront configuration; maybe Cloudfront, in compressing the files, is removing the CORS headers that S3 is providing.</p></li><li><p>I found a <a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/header-caching.html#header-caching-web-cors\">documentation page about Cloudfront and CORS</a>. I whitelisted four headers in my Cloudfront Default Cache Behavior Settings:</p><ul><li><code>Access-Control-Request-Headers</code></li><li><code>Access-Control-Request-Methods</code></li><li><code>Origin</code></li><li><code>Referer</code></li></ul></li><li><p>Now none of my CURL requests are giving me any CORS headers in the response; even the ones that used to work</p></li><li><p>But the CORS error is gone from Firefox now. <Footnote>This was the most confusing part of debugging. Why does it work in the browser but the proper headers don't show up in CURL?</Footnote></p></li><li><p>And from Chrome.</p></li><li><p>After clearing the browser cache, the page looks fine on my girlfriend's computer. I think I fixed this.</p></li><li><p>I wonder if I need to clear the Cloudfront cache or add a cachebusting query onto the <code>&lt;link&gt;</code> tag? Eh, seems like a lot of work, maybe not worth it if everything looks ok.</p></li><li><p>The end.</p></li></ul><Note title=\"Update from the next day\"><p>It looks like my <code>orient-fonts.css</code> file is being requested twice: once from the <code>&lt;link&gt;</code> tag and once as an XHR request so that <a href=\"https://elementqueries.com/\">EQCSS</a> can analyze the stylesheets and render the element queries properly. It's those link tag requests that have the CORS headers, but the XHR requests do not.</p></Note><p>If I had any takeaways, they would have to be that debugging these kinds of issues (especially on systems you don't know well) can be tricky, and it helps to have knowledge of the invariants of the system. In this case, I had done my background research on CORS errors so I knew what the ultimate solution would look like: there were response headers that weren't showing up when I expected them to. I also knew that because <em>some</em> CURL queries responded with the correct CORS headers, there was a problem with some configuration between S3 and the browser: one of the layers working in there was stripping away the response headers I wanted. I was then able to examine each layer to narrow down where the problem lies, then read the documentation specific to that layer (thank goodness that documentation exists) to configure the CDN correctly.</p><p>This was an interesting case study since it's in an unfamiliar area (HTTP responses and CDN configuration) of a very familiar field (web development). Most of the time when I come across these confusing types of issues I look through Stack Overflow and add the few lines of code that solves it. <Footnote>This is a skill in itself: knowing which Stack Overflow solution fits the problem domain and understanding where the lines of code need to go. In those situations, I feel like SO is standing in for good documentation, in that I couldn't figure out through documentation alone why an issue was taking place and what code I needed to write in order to solve it.</Footnote> This CORS issue had come up enough times that I decided that I wanted to have a greater understanding of what's going on and what needed to be fixed.</p><p>I hope to write this kind of blog post again in the future. Deep-diving and solving these types of problems is an intrinsic part of software development, and I like having insight into the thought processes I go through in order to fix a bug. Hopefully if I do this again I can have points of reference for my problem-solving thought process to see how this skill changes over time.</p></article>",
            "url": "https://jameslittle.me/blog/2019/debugging-cors",
            "title": "My Thought Process while Debugging a CORS error",
            "summary": "Piggybacking on the previous post, a stream-of-thought post describing my own process for fixing a CORS error. Ends up as a Cloudfront configuration debugging session.",
            "date_modified": "2019-08-24T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2019/cors",
            "content_html": "<article><p>&quot;CORS&quot; errors are a certain type of web development errors that can be pretty confusing. <em>Cross-Origin Resource Sharing</em> related errors pop up when the web browser is trying to protect you from potential security vulnerabilities. When you don't expect them, though, they can be pretty irritating—the error messages don't make it entirely clear what you need to do to resolve the problem, and CORS itself is a complex enough topic that you won't find any quick resolution steps on the internet.</p><Figure caption=\"An image of a CORS error in the Firefox developer tools\"><Image src=\"https://files.jameslittle.me/images/inspector-error.png\"></Image></Figure><p>Why do CORS errors occur in the first place? You nearly always see them when the following three cases are true: when the browser is</p><ol><li>asked to load a remote resource (like a script, font, a page via AJAX, a WebGL texture, but not, notably, an image via the <code>&lt;img&gt;</code> tag) and that resource is</li><li>from an <em>external domain</em>, i.e. a domain that isn't the same as the one in your address bar, but</li><li>the server doesn't specify (by sending the correct HTTP headers) that the original domain is allowed to use that resource.</li></ol><p>When all three of those cases are true, the browser will stop itself from loading the file, and will throw an error like the one above in the Javascript console. This might manifest as a font that doesn't load, an AJAX call that doesn't succeed, or other &quot;why won't this show up&quot; kinds of problems.</p><p><strong>Why does the browser stop remote resources from loading?</strong> It's a permissions issue: the browser wants to make sure that the external server has given its blessing to the website trying to load its content.</p><p>Imagine I want to steal information from a victim website. I set up an evil website that loads a script from the victim site's server. Without CORS protections in place, my evil site can download and run the victim site's script and send the victim site's data back to me. In this way, servers can protect themselves from inappropriate content access.</p><p>Unfortunately, this means that if you build a site and an external service from which it loads data, you'll have to set up this external service so that it knows it is allowed to serve data when the site is asking for it.</p><p>In the case of the <a href=\"https://bowdoinorient.com\">Bowdoin Orient's site</a>, the font CDN <Footnote>Content Distribution Network: another server whose job it is to cache and serve static files very quickly.</Footnote> lives on a different server from the actual site itself. That means the original page (the origin, or <code>https://bowdoinorient.com</code>) is trying to load content from a different domain (<code>font-cdn.bowdoinorient.co</code>). If we don't set up the font CDN server to allow itself to serve content to pages on <code>bowdoinorient.com</code>, the browser will refuse to load that content, meaning (in this case) our fonts will break.</p><p>My goal is to create a short guide that explains what's going on when you encounter these weird error messages, and to describe what the browser expects from the files it downloads and why.</p><h2>HTTP and Headers</h2><p>Let's talk about the HyperText Transfer Protocol.</p><p>What happens when you go to a website, like <code>https://jameslittle.me</code>? On a high level, your browser sends an HTTP request (which is just a bit of text) to my server, and my server, via a program like <a href=\"http://httpd.apache.org/\">Apache</a> that runs continuously and is built to answer web requests, sends back an HTTP response with the contents of my web page.</p><p>Every time a web page loads, several of these HTTP requests are sent: the first one is for the HTML document that was requested, and the rest are for any images, scripts, fonts, or stylesheets that the HTML document says is needed. The first one is directly related to the page you asked for in your browser's address bar; any others are automatically sent by the browser as specified by the first document the browser gets back. For each request that gets sent, the server to which it gets sent responds with the data the browser asked for. Those request/response pairs make up the contents of the web page, and control what your browser displays to you.</p><Figure caption=\"The HTTP headers for both a request (on the bottom) and a response (on the top).\"><Image src=\"https://files.jameslittle.me/images/inspector-headers.png\"></Image></Figure><p>We can dig into the request/response pairs in greater depth by looking at them in the Web Inspector. <Footnote>I use Firefox, so that's where these inspector screenshots come from. But every reasonable web browser has an inspector these days, and all of them let you look at the contents and headers of an HTTP request and response.</Footnote> Each request and response has two parts: the <em>headers</em> and the <em>payload</em>.</p><p><strong>Headers:</strong> The headers define configuration and other metadata for the message. They are plain-text key-value pairs that go at the beginning of both HTTP requests and responses. HTTP request headers are messages that the <em>browser</em> wants to tell the <em>server</em>, while HTTP response headers are messages that the <em>server</em> wants to tell the <em>browser</em>.</p><p><strong>Payload:</strong> The payload for an HTTP <em>response</em> will almost always be the contents of the requested file. HTTP requests can sometimes have a payload, though most of the time this payload is empty — usually, an HTTP request only consists of headers describing the file the browser is asking for.</p><Note><p>For more information about what HTTP requests and responses look like (and what they can do), <a href=\"https://jvns.ca\">Julia Evans</a> has a zine coming out that does a fantastic job explaining it. When she publishes it, I'll update this post with the link here.</p><p>Update: Julia has been tweeting about HTTP like crazy! Here are some tweets:</p><ul><li><a href=\"https://twitter.com/b0rk/status/1160933788949655552\">Using HTTP APIs</a></li><li><a href=\"https://twitter.com/b0rk/status/1164181027469832196\">HTTP headers</a></li><li><a href=\"https://twitter.com/b0rk/status/1161262574031265793\">HTTP Response headers</a></li><li><a href=\"https://twitter.com/b0rk/status/1160185182323970050\">Security headers</a></li><li><a href=\"https://twitter.com/b0rk/status/1161283690925834241\">custom headers</a></li><li>Request methods <a href=\"https://twitter.com/b0rk/status/1161679906415218690\">part one</a> and <a href=\"https://twitter.com/b0rk/status/1161680137865367553\">part two</a></li><li><a href=\"https://twitter.com/b0rk/status/1161679906415218690\">HTTP request methods</a></li><li><a href=\"https://twitter.com/b0rk/status/1155493682885341184\">the Same Origin policy</a> and <a href=\"https://twitter.com/b0rk/status/1163460967067541504\">why it matters</a>.</li></ul><p>Update 2: <a href=\"https://wizardzines.com/zines/http/\">Here is the zine!</a></p></Note><h2>How HTTP headers relate to CORS errors</h2><p>As I described earlier, CORS errors occur when the server hasn't specified that the browser is allowed to load the resource. That permission is communicated using an HTTP header on the response: the server will add a header that says &quot;If any page on <code>bowdoinorient.com</code> downloads a file from me, it is allowed to use it.&quot;</p><p>Remember: HTTP headers are key-value pairs in the beginning of an HTTP message. The one that describes this permission granting has a key of <strong><code>Access-Control-Allow-Origin</code></strong>, and has a value of the <em>origin</em> allowed to use that file (in this example, <strong><code>bowdoinorient.com</code></strong>). If that key-value pair is present on an HTTP response from an external server (like a font CDN), any time a page on <code>bowdoinorient.com</code> wants to load that font, the browser will allow that to happen.</p><Note><p>In the case of <code>GET</code> requests, the file is always downloaded, but if the browser finds itself in a situation that would break the CORS policy, it will refuse to load the file's contents: the script won't run, the stylesheet won't get used, etc.</p><p><code>POST</code> requests are different: the browser typically sends a canary request (called an <code>OPTIONS</code> request) to check what it's allowed to do, and if it finds it is allowed to make the POST request, it does so.</p></Note><p>Therefore, if you're getting console warnings about CORS headers not being properly included, it means you have to change the configuration on your server: your server needs to be including HTTP headers in the response so that the browser knows it's allowed to use the file it downloaded.</p><h2>What kinds of headers should I include?</h2><p>It sort of depends on what your browser is asking for — while the console error messages might not immediately be clear, you can usually tell which header is missing from the error message. In the example above, the server needs to attach the <strong><code>Access-Control-Allow-Origin</code></strong> header with a value that says that <code>bowdoinorient.com</code> pages are allowed to use the font file.</p><p>I mentioned above that the header's value can be set as <strong><code>bowdoinorient.com</code></strong>, and that will allow pages on <code>bowdoinorient.com</code> to load the resource. But we could also configure the value to be <strong><code>*</code></strong>, which would specify that any site is allowed to use that resource. <Footnote>General purpose CDNs, like Google Fonts, will have this <code>*</code> as the value for their <code>Access-Control-Allow-Origin</code> header.</Footnote></p><p>CORS errors can manifest in different ways, since there are different permissions that a server can specify. There are more headers that give more granular permissions to browsers. These headers might include:</p><p><strong><code>Access-Control-Allow-Methods</code></strong>: describes which HTTP methods (GET, POST, PUT, DELETE, etc.) are allowed to be used on a given URI. When you use Javascript to make an AJAX request, sometimes it will send a <em>preflight request</em>: an additional request beforehand to see what sorts of requests the browser is allowed to make before it actually makes the request. The server will respond with this header to let the browser (and, ultimately, you) know what kinds of HTTP methods you can use next.</p><p><strong><code>Access-Control-Allow-Headers</code></strong>: describes which request headers are allowed to be sent while asking for a given resource. For example, the browser (again, through Javascript) might specify in a request header that it wants JSON-only responses (<code>content-type: JSON</code> would be the header tacked onto the HTTP request). If you send a server a header it doesn't expect, it might reject the request altogether.</p><h2>Conclusion</h2><p>When struggling with CORS errors, the concepts I always have to remind myself are:</p><ol><li>The file is usually being properly downloaded, but the browser is blocking the file from being used</li><li>The server needs to be changed to give the browser permission to use that file</li><li>That change needs to be a new header that gets included with the HTTP response</li></ol><p>Those three concepts are the biggies. And ultimately I always feel like the fix was something simple that just requires a large research journey. Security is just like that, I guess.</p><Note title=\"Update\"><p><a href=\"/blog/2019/cors-debug/\">In another post, I wrote about a CORS error that I encountered and fixed.</a></p></Note></article>",
            "url": "https://jameslittle.me/blog/2019/cors",
            "title": "Why do we encounter CORS errors?",
            "summary": "An explainer describing what a Cross-Origin Resource Sharing error is, why they exist, and how to fix one once you come across it.",
            "date_modified": "2019-08-18T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2019/next",
            "content_html": "<article><p>I'm heading back to <a href=\"https://stripe.com\">Stripe</a> in San Francisco to work on the <a href=\"https://stripe.com/terminal\">Terminal SDK team</a>!</p><p>But yikes, I had a busy spring. I <a href=\"https://www.instagram.com/p/ByGV9FMANnw/\">finished</a> my <a href=\"/classes\">Bowdoin career</a>, presented and submitted <a href=\"/blog/2019/bowdoin-article\">my thesis</a>, presented some research I had been working on with the Art History department, and ran a Triathlon. Whew!</p><p>I'll be at home relaxing for a while, enjoying the hometown I've been away from for the past four years. In July, I'll be moving out to San Francisco, where I've spent the past two summers. We found a cute apartment in the Sunset District, and I'll be spending a bit of time getting settled there. Soon after I move, my friends and I are hoping to hike the <a href=\"http://johnmuirtrail.org/\">John Muir trail</a>. Then, finally, I'll return to Stripe, where I interned in the summer of 2018. I start in early August.</p><p>I worked on the iOS Dashboard team at Stripe when I interned there. Since then, I've learned that that team was mildly restructured. I'll be joining the Terminal SDK team, a team which works on Stripe's (brand new) physical point-of-sale product. I got the opportunity to play with Terminal a little bit last summer, and it seems like an awesome product with a really energetic team behind it. I'm really excited to be part of Stripe's foray into the physical world!</p><p>For now, I'm resting, reading, spending time with friends and family, and finally taking a look at my long list of projects I wanted to tackle once I got some free time. And, as always, looking forward to what's next.</p></article>",
            "url": "https://jameslittle.me/blog/2019/next",
            "title": "Next",
            "summary": "Starting work at Stripe.",
            "date_modified": "2019-05-31T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2019/bowdoin-article",
            "content_html": "<article><p>Rebecca Goldfine of the Bowdoin Communications Office wrote <a href=\"https://www.bowdoin.edu/news/2019/03/james-little-19-teaches-computers-to-teach-themselves.html\">a really nice piece</a> about my honors project, where I've been working on synthetic training data for ML models. I'm really thrilled that they wanted to show off my work!</p><p>I've been keeping an <a href=\"https://honors.jameslittle.me\">online lab notebook</a> for my project all year -- you can visit that site to explore what I've been doing in more detail.</p></article>",
            "url": "https://jameslittle.me/blog/2019/bowdoin-article",
            "title": "Bowdoin's Article about my Honors Project",
            "summary": "Bowdoin's article about my Honors Project",
            "date_modified": "2019-04-05T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2019/tensorflow-object-detection",
            "content_html": "<article><p>I’ve been working on image object detection for my senior thesis at <a href=\"https://www.bowdoin.edu/computer-science/index.html\">Bowdoin</a> and have been unable to find a tutorial that describes, at a low enough level (i.e. with code samples), how to set up the <a href=\"https://github.com/tensorflow/models/tree/master/research/object_detection\">Tensorflow Object Detection API</a> and train a model with a custom dataset. This aims to be that tutorial: the one I wish I could have found three months ago.</p><h2>Background</h2><p>I don’t know much about advanced Machine Learning concepts, and I know even less about Tensorflow. If you’re like me, you’ve heard of Tensorflow as the best Machine Learning framework available today<Footnote>Don’t @ me</Footnote>, and you want to use it for a very specific use case (in my case, object detection). You also don’t want to spend months studying what seem to be Tensorflow-specific vocabulary and concepts.</p><p>Similarly, if you’re like me, you have some familiarity with Linux and Python. I’m a programmer more than I am an ML researcher, and you’ll probably grok this article most if you’re in the same boat.</p><p>Finally, I assume you have Tensorflow installed—at the very least, I assume you can run the “getting started” block of code on the <a href=\"https://www.tensorflow.org/tutorials/\">Tensorflow Tutorial page</a>. If that runs without any errors, you should be good to go. If not, this might not be the tutorial for you, and you should get that working before coming back here.</p><h2>The Plan</h2><p>Since this is a complicated process, there are a few steps I’ll take you through (and therefore, a few sections this article will be broken into):</p><ol><li>Set up the Object Detection API</li><li>Get your datasets (both training and testing) in a format Tensorflow can understand</li><li>Train and test the API with those datasets</li></ol><p>Finally, during the training step, we’ll set up <a href=\"https://www.tensorflow.org/guide/summaries_and_tensorboard\">TensorBoard</a>, a browser-based training visualization tool, to watch our training job over time. Using this model in a different environment (like a mobile device) is, unfortunately, beyond the scope of this article.</p><h2>Step One: Set up the Object Detection API</h2><p>This section will lead you through four steps:</p><ul><li>Download the Object Detection API’s code and copy the relevant parts into a new subdirectory, <code>my_project</code></li><li>Install and compile Protocol Buffers</li><li>Install and build the python modules necessary for the API</li><li>Test that the API is ready for use</li></ul><p>You’ll need a new directory for all of our future work steps, so start by creating one and changing into it.</p><pre data-language=\"bash\">$ mkdir obj_detection\n\n$ cd obj_detection\n</pre><p>The Object Detection API is part of a <a href=\"https://github.com/tensorflow/models/graphs/contributors\">large, official repository</a> that contains lots of different Tensorflow models. We only want one of the models available, but we’ll download the entire Models repository since there are a few other configuration files we’ll want.</p><pre data-language=\"bash\">$ git clone https://github.com/tensorflow/models.git\n</pre><p>Once that download is over, we’ll copy the files into a new directory.</p><pre data-language=\"bash\">$ mkdir my_project\n\n$ cp -r models/research/object_detection my_project\n\n$ cp -r models/research/slim my_project\n\n$ cp models/research/setup.py my_project\n</pre><p>The Object Detection API uses <a href=\"https://developers.google.com/protocol-buffers/\">Protocol Buffers</a> (Protobufs), a message serialization and transmission framework, for some reason I’m not entirely sure about. We need to download and compile Protobufs, however, to get the API to work.</p><p>Downloading and unzipping Protobufs will create a <code>bin</code> directory in your <code>obj_detection</code> directory.</p><pre data-language=\"bash\">$ wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n\n$ unzip protobuf.zip\n</pre><p>At this point, you’ll need to compile the protobufs. You need to move into the <code>my_project</code> directory and run the compilation script from there, since there are import steps that make assumptions about the location from which you’re running the script.</p><pre data-language=\"bash\">$ cd my_project\n\n$ ../bin/protoc object_detection/protos/*.proto --python_out=.\n</pre><p>With Protobufs downloaded and compiled, the Object Detection Python module has to be built. This will create a <code>build</code> directory in your <code>my_project</code> directory.</p><p>The following commands should be run from your <code>my_project</code> directory: the place you <code>cd</code>-ed into in the last step.</p><pre data-language=\"bash\">$ export PYTHONPATH=$(pwd):$(pwd)/slim/:$(pwd)/lib/python3.4/site-packages/:$PYTHONPATH\n\n$ python3 setup.py install --prefix $(pwd) # Lots of output!\n\n$ python3 setup.py build\n</pre><p>These commands will first designate the current directory (and some subdirectories) as locations Python is allowed to read modules from and write modules to. The second command will install all the various Python modules necessary for the API to the current directory, and the last command will build those modules.</p><p>When you’re done, you’ll have a directory structure that looks like this:</p><pre data-language=\"bash\">$ ls # From obj_detection\nbin  include  models  my_project  protobuf.zip  readme.txt\n\n$ cd my_project\n\n$ ls\nbin  build  dist  lib  object_detection  object_detection.egg-info  setup.py  slim\n</pre><p>Finally, the following command will test your setup: if you get an <code>OK</code> at the end, you’re good to go.</p><pre data-language=\"bash\"># From my_project\n\n$ python3 object_detection/builders/model_builder_test.py\n</pre><h3>Troubleshooting</h3><p>You might <em>not</em> get an <code>OK</code> at the end. Unfortunately, I can’t troubleshoot your setup for you, but I can tell you that when I was troubleshooting my own, the most finicky part I encountered was setting the <code>PYTHONPATH</code> correctly; we did this above with the line that began with <code>export</code>.</p><p>StackOverflow actually works pretty well to figure out what other things you should put in your <code>PYTHONPATH</code> I had an issue finding <code>libcublas.so.9.0</code>; for me, that meant running <code>$ export PYTHONPATH=/usr/local/cuda-9.0/lib64/:$PYTHONPATH</code>.</p><p>If you leave the project for a while and come back, you’ll have to run all the <code>export</code> lines again to restore your <code>PYTHONPATH</code>. I created a bash file that ran all the necessary <code>export</code> commands, and I would run <code>$ source setup_python_path.sh</code> whenever I logged on.</p><p>For completion’s sake, I also include the line <code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.0/targets/x86_64-linux/lib/</code> in my script; running the test script wouldn’t work without it. This is probably relevant only to my computer, but it might help you out too.</p><h2>Step Two: Preparing the Datasets</h2><p>Since the API we’re using is based on object detection, you’ll need to have a dataset you want to work with. This dataset should be comprised of images and annotations in whatever format you choose: I had JPGs numbered <code>0.jpg</code> through <code>9999.jpg</code> and a CSV file with the coordinates of the objects I’m detecting. <Footnote>Getting this dataset and figuring out how to annotate it is up to you — since we’re dealing with <em>your</em> dataset here, it wouldn’t make sense for me to give you instructions for doing this.</Footnote></p><Image src=\"https://files.jameslittle.me/images/files.png\"></Image><p>For each object in an image, you should have <code>x1</code>, <code>x2</code>, <code>y1</code> and <code>y2</code> coordinates available, where <code>(x1, y1)</code> is the upper left corner of the rectangle and <code>(x2, y2)</code> is the lower right corner of the rectangle.</p><Image src=\"https://files.jameslittle.me/images/box.png\"></Image><p>You’ll probably have two of these datasets, one large one for training and one smaller one for testing. We’ll be taking the two datasets and transforming each of them into <a href=\"https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564\"><code>.tfrecord</code> files:</a> large binary files that contain a complete representation of the entire dataset.</p><p>I wrote a Python script to do this. The script reads in each image in a directory, reads the corresponding line in a CSV file, and appends the TFRecord with the image data and the associated coordinate data. Your script will probably look different since this is based on my dataset and this will be based on yours.</p><p>Remember: If you’ve logged out of your shell since setting up your Python path, you’ll have to set it up again before running this script.</p><pre data-language=\"python\">import tensorflow as tf\nfrom object_detection.utils import dataset_util\n\nflags = tf.app.flags\n\n# Here is where the output filename of the TFRecord is determined. Change this,\n# perhaps to either `training.tfrecord` or `testing.tfrecord`.\nflags.DEFINE_string('output_path', 'output.tfrecord', 'Path to output TFRecord')\nFLAGS = flags.FLAGS\n\n\ndef create_tfrecord(filename, coords):\n    # You can read these in from your image, or you can hack it and\n    # hardcode the dimensions in.\n    height = 480\n    width = 640\n\n    filename = str.encode(filename)\n\n    with open(filename, 'rb') as myfile:\n        encoded_image_data = myfile.read()\n\n    image_format = b'jpeg'  # b'jpeg' or b'png'\n\n    xmins = [coords[0] / width]\n    xmaxs = [coords[1] / width]\n    ymins = [coords[2] / height]\n    ymaxs = [coords[3] / height]\n\n    # Here, you define the &quot;classes&quot; you're detecting. This setup assumes one\n    # class, named &quot;Ball&quot;. Your setup will probably look different, so be sure\n    # to change these lines.\n    classes_text = [b'Ball']\n    classes = [1]\n\n    tfrecord = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': dataset_util.int64_feature(height),\n        'image/width': dataset_util.int64_feature(width),\n        'image/filename': dataset_util.bytes_feature(filename),\n        'image/source_id': dataset_util.bytes_feature(filename),\n        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n        'image/format': dataset_util.bytes_feature(image_format),\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n        'image/object/class/label': dataset_util.int64_list_feature(classes),\n    }))\n    return tfrecord\n\n\ndef main(_):\n    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n\n    with open(&quot;annotations.csv&quot;) as fp:\n        line = fp.readline()\n        while line:\n            data = line.split(&quot;,&quot;)\n            tfrecord = create_tfrecord(&quot;img/out/{}.jpg&quot;.format(data[0]), data[1:])\n            writer.write(tfrecord.SerializeToString())\n            line = fp.readline()\n        writer.close()\n\n  print(&quot;Done.&quot;)\n\n\nif __name__ == '__main__':\n    tf.app.run()\n</pre><p>Make sure you know when your script is done running — a <code>print()</code> call should do just fine. When you have your two completed <code>.tfrecord</code> files (one for the training dataset and one for the testing dataset), put them somewhere and hold onto them for later.</p><h2>Step 3: Training and Testing</h2><p>While this tutorial describes how to train the Object Detector API using your own data, it isn’t describing how to train a model <em>from scratch</em>. This distinction is important: instead of starting from nothing, we’ll be starting with an existing, generalized object detection model and continuing to train it based on our own data. Models, in Tensorflow’s world, can simultaneously be independent entities and checkpoints, meaning that after training a model for a long while, you can either pack up and call it a day and use that model in the wild, <em>or</em> you can stop for a bit and resume training later. We’re doing more of the second option, although instead of resuming the exact same training, we’re nudging an existing model (which I’ll call the <em>baseline model</em>) towards the object detection we want it to be able to perform. This lets us get some results fairly quickly — the existing models have been trained on very high powered computers for a very long time, and our tweaks take only a little bit of time.</p><p>The Object Detection API provides <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">a set of these baseline models</a>; they allow you to either use them out of the box or initialize new models based on them. I used “SSD with Inception v2 configuration for MSCOCO Dataset,” but you might want to use a different baseline model depending on what you’re trying to detect. To download the one I used, run the following command:</p><pre data-language=\"bash\">$ wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_oid_14_10_2017.tar.gz\n\n$ tar -zxvf faster_rcnn_inception_resnet_v2_atrous_oid_14_10_2017.tar.gz\n</pre><p>Training and testing happen at the same time — the scripts in the API run a testing step after every training step. To begin the training/testing, we’ll first need a configuration file; the configuration file framework you use depends on which baseline model you’re using. (If you’re not using a baseline model, you can either write your own or modify one of the given ones.)</p><p>The configuration I used is below, and originally comes from <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_inception_v2_coco.config\">the Object Detection API’s sample configs</a>. The file gets saved in your working directory as <code>mymodel.config</code> (although the actual filename doesn’t totally matter). I’ve marked within the file the lines you should modify, and kept the original comments as well.</p><pre>model {\n  ssd {\n    num_classes: 1 # Change this!\n    box_coder {\n      faster_rcnn_box_coder {\n        y_scale: 10.0\n        x_scale: 10.0\n        height_scale: 5.0\n        width_scale: 5.0\n      }\n    }\n    matcher {\n      argmax_matcher {\n        matched_threshold: 0.5\n        unmatched_threshold: 0.5\n        ignore_thresholds: false\n        negatives_lower_than_unmatched: true\n        force_match_for_each_row: true\n      }\n    }\n    similarity_calculator {\n      iou_similarity {\n      }\n    }\n    anchor_generator {\n      ssd_anchor_generator {\n        num_layers: 6\n        min_scale: 0.2\n        max_scale: 0.95\n        aspect_ratios: 1.0\n        aspect_ratios: 2.0\n        aspect_ratios: 0.5\n        aspect_ratios: 3.0\n        aspect_ratios: 0.3333\n        reduce_boxes_in_lowest_layer: true\n      }\n    }\n    image_resizer {\n      fixed_shape_resizer {\n        height: 300\n        width: 300\n      }\n    }\n    box_predictor {\n      convolutional_box_predictor {\n        min_depth: 0\n        max_depth: 0\n        num_layers_before_predictor: 0\n        use_dropout: false\n        dropout_keep_probability: 0.8\n        kernel_size: 3\n        box_code_size: 4\n        apply_sigmoid_to_scores: false\n        conv_hyperparams {\n          activation: RELU_6,\n          regularizer {\n            l2_regularizer {\n              weight: 0.00004\n            }\n          }\n          initializer {\n            truncated_normal_initializer {\n              stddev: 0.03\n              mean: 0.0\n            }\n          }\n        }\n      }\n    }\n    feature_extractor {\n      type: 'ssd_inception_v2'\n      min_depth: 16\n      depth_multiplier: 1.0\n      conv_hyperparams {\n        activation: RELU_6,\n        regularizer {\n          l2_regularizer {\n            weight: 0.00004\n          }\n        }\n        initializer {\n          truncated_normal_initializer {\n            stddev: 0.03\n            mean: 0.0\n          }\n        }\n        batch_norm {\n          train: true,\n          scale: true,\n          center: true,\n          decay: 0.9997,\n          epsilon: 0.001,\n        }\n      }\n      override_base_feature_extractor_hyperparams: true\n    }\n    loss {\n      classification_loss {\n        weighted_sigmoid {\n        }\n      }\n      localization_loss {\n        weighted_smooth_l1 {\n        }\n      }\n      hard_example_miner {\n        num_hard_examples: 3000\n        iou_threshold: 0.99\n        loss_type: CLASSIFICATION\n        max_negatives_per_positive: 3\n        min_negatives_per_image: 0\n      }\n      classification_weight: 1.0\n      localization_weight: 1.0\n    }\n    normalize_loss_by_num_matches: true\n    post_processing {\n      batch_non_max_suppression {\n        score_threshold: 1e-8\n        iou_threshold: 0.6\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SIGMOID\n    }\n  }\n}\n\ntrain_config: {\n  batch_size: 24\n  optimizer {\n    rms_prop_optimizer: {\n      learning_rate: {\n        exponential_decay_learning_rate {\n          initial_learning_rate: 0.004\n          decay_steps: 800720\n          decay_factor: 0.95\n        }\n      }\n      momentum_optimizer_value: 0.9\n      decay: 0.9\n      epsilon: 1.0\n    }\n  }\n  fine_tune_checkpoint: &quot;YOUR-BASELINE-MODEL/model.ckpt&quot; # Change this to point to your baseline model -- in the file you just downloaded\n  from_detection_checkpoint: true\n  # Note: The below line limits the training process to 200K steps, which we\n  # empirically found to be sufficient enough to train the pets dataset. This\n  # effectively bypasses the learning rate schedule (the learning rate will\n  # never decay). Remove the below line to train indefinitely.\n\n  num_steps: 400000\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n  data_augmentation_options {\n    ssd_random_crop {\n    }\n  }\n}\n\ntrain_input_reader: {\n  tf_record_input_reader {\n    input_path: &quot;YOUR-TRAINING-TFRECORD/training.tfrecord&quot;\n  }\n  label_map_path: &quot;YOUR-LABELMAP/labelmap.txt&quot;\n}\n\neval_config: {\n  num_examples: 8000\n  # Note: The below line limits the evaluation process to 10 evaluations.\n  # Remove the below line to evaluate indefinitely.\n  max_evals: 10\n}\n\neval_input_reader: {\n  tf_record_input_reader {\n    input_path: &quot;YOUR-TESTING-TFRECORD/testing.tfrecord&quot;\n  }\n  label_map_path: &quot;SAME-LABELMAP-AS-ABOVE/labelmap.txt&quot;\n  shuffle: false\n  num_readers: 1\n}\n</pre><p>Finally, you’re ready to run the detector. Put the following into a file called <code>run.sh</code>:</p><pre data-language=\"bash\">PIPELINE_CONFIG_PATH=&quot;YOUR-CONFIG.config&quot;\nMODEL_DIR=&quot;./object_detection/modeldir&quot;\nNUM_TRAIN_STEPS=50000 # Change this if necessary\nSAMPLE_1_OF_N_EVAL_EXAMPLES=1\n\npython3 object_detection/model_main.py \\\n    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\n    --model_dir=${MODEL_DIR} \\\n    --num_train_steps=${NUM_TRAIN_STEPS} \\\n    --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n    --alsologtostderr\n</pre><p>And finally, you can run that script (<code>$ ./run.sh</code>) to get the training job started.</p><h3>TensorBoard</h3><p>TensorBoard is a program that comes with Tensorflow that starts up a local web server and hosts a dashboard to show the progress of the training and testing job. You can set up Tensorboard to watch your model directory (<code>./object_detection/modeldir</code>) and it can describe the progress of your training job.</p><p>In a new terminal (so as to not disturb your training job), navigate back to your <code>my_project</code> directory, reconfigure your Python path, and then run:</p><pre data-language=\"bash\">$ tensorboard --logdir=./object_detection/modeldir\n</pre><p>With that running, you can navigate to http://localhost:6006 and watch the graphs go by over the next few hours or days</p><h2>Conclusion</h2><p>I wrote this up because I couldn’t find a tutorial online that went through these same steps, so I hope this ends up being helpful for the next person who wants to embark on this same journey.</p><p>I’m also sure I got some things wrong; reach out if I have an error and I’ll work to correct it.</p><hr><h2>Other Resources</h2><p>I clearly looked up a lot of ways other people were doing this. Unfortunately, due to the nature of online research, it will be impossible for me to list everything I encountered on the internet that helped me along the way. However, here is an incomplete list of sources (and an implied list of apologies to those who I forgot):</p><ul><li>The <a href=\"https://github.com/tensorflow/models/tree/master/research/object_detection/g3doc\">official Object Detection docs</a>: these articles (<a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">1</a> <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md\">2</a> <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/preparing_inputs.md\">3</a> <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md\">4</a> <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md\">5</a> <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md\">6</a> <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/oid_inference_and_evaluation.md\">7</a>) were the most helpful.</li><li>This <a href=\"https://deeplearninganalytics.org/blog/building-toy-detector-with-object-detection-api\">toy detector tutorial</a> by Priya Dwivedi</li><li><a href=\"https://medium.com/@WuStangDan/step-by-step-tensorflow-object-detection-api-tutorial-part-1-selecting-a-model-a02b6aabe39e\">This Medium article</a> by Daniel Stang, and <a href=\"https://medium.com/@WuStangDan/step-by-step-tensorflow-object-detection-api-tutorial-part-2-converting-dataset-to-tfrecord-47f24be9248d\">its sequel</a></li><li>An <a href=\"https://www.oreilly.com/ideas/object-detection-with-tensorflow\">O’Reilly article</a> by Justin Francis</li></ul></article>",
            "url": "https://jameslittle.me/blog/2019/tensorflow-object-detection",
            "title": "How to train the Tensorflow Object Detection API with custom training data",
            "summary": "A guide to setting up a Tensorflow Object Detection system and training it with your own self-annotated data.",
            "date_modified": "2019-01-25T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2018/developing-deploying-orient",
            "content_html": "<article><p>I moved the <a href=\"http://bowdoinorient.com\">Bowdoin Orient site</a> from a custom CMS to a WordPress-based system over a year ago; since that time, I’ve struggled to find a proper development and deployment workflow that made sense for the Orient. This year, as the Orient welcomes four new members onto its web staff, I’ve been working to ensure that the website could easily be developed and deployed.</p><p>The system I built was based on solving the core problem of WordPress development: that the disadvantages of using exclusively local or remote development outweigh the simplicity of those two methods. I wanted to ensure that we could avoid those disadvantages and fulfill other requirements while using the best best practices I know of. Furthermore, I wrote it in Ruby to familiarize myself with the language used most often at <a href=\"https://stripe.com\">Stripe</a>, where I interned this past summer.</p><h2>The problem</h2><p>WordPress makes it notoriously hard to set up staging environments. There’s configuration that takes place in PHP files and other configuration that takes place in the application’s database. Migrating the application from one server to another is so difficult that paid tools exist to do it properly. Local development either requires manually configuring daemons and local servers or installing MAMP. I wanted to build a solution that required as little local modification as possible, while still providing as much access to the code as possible.</p><h2>More Project Requirements</h2><ul><li><p><strong>It should be easy to write new code.</strong> I don’t want the development or deployment system to get in the way of features that need to be written; in addition, I don’t want most of the code I write to be part of the deployment system. It should be simple to use and simple to maintain.</p></li><li><p><strong>Servers shouldn’t need ongoing maintenance.</strong> I’m going to graduate soon. Whoever works on the Bowdoin Orient site next won’t be interested in the same things I’m interested in. Development on the site needs to be able to happen even if nobody is massaging the deployment system into place.</p></li><li><p><strong>The workflow should encourage code review and transparency.</strong> One deployment system is to have <em>no</em> deployment system, and just write all code on the server, live. This is known as “cowboy coding,” which is canonically <a href=\"https://en.wikipedia.org/wiki/Cowboy_coding#Disadvantages\">bad</a>.</p><p>The system should make it easy to write new code, but it should make it <em>drastically difficult</em> to write that new code on the actual web server. We use Git and Github for version control, and I wanted to ensure that an administrator could approve code changes before they made it into the live site.</p></li></ul><h2>Methodology</h2><p>The foundation of the project is a remote web server and database that hosts different instances of the Orient website. Also running on this server is a program that can automatically spin up and tear down new instances of the site and show users how to synchronize code between their local machine and the server.</p><p>When a new instance is created, the Running on a VPS is a Ruby application that keeps track of development environments, or <em>devenv</em> s. When a new <em>devenv</em> is made, the user specifies a subdomain, and the application performs a series of setup steps:</p><ol><li>It downloads the master branch of the repository into a new folder, accessible by Apache.</li><li>It gets the latest database backup, exported by a cron job.</li><li>It finds and replaces the original url (<code>bowdoinorient.com</code>) at which the new domain that the staging site will be available (<code>{something}.test.bowdoinorient.co</code>).</li><li>It creates a new MySQL database and a new MySQL user.</li><li>It imports the modified database backup into that new staging database.</li><li>It writes <code>wp-config.php</code> and <code>.htaccess</code> files with accurate database and domain information.</li></ol><p>When this is complete, users use <code>scp</code> to copy the entire directory onto their local computer. They can make edits locally, create new Git branches, and make commits. As files are changed, developers can use <code>rsync</code> to synchronize local changes with the server. Developers also have full access to the MySQL database.</p><p>This lets developers have all the benefits of space on a VPS—server infrastructure is managed externally, nobody has to do any weird things with their hosts file to get domains to work, and the site is available everywhere—while also having all the benefits of local development—they can use whichever editor feels comfortable, run preprocessing steps locally, and can have a quick refresh-to-analyze cycle. This is the most optimal system I’ve found for setting up a hybridized local-remote development.</p><h2>Future Work</h2><ul><li>This whole project ended up sounding a lot like containerization; I’d love to get more familiar with containerization tools to do this even better.</li><li>I took security mildly into account, but there are still some holes I’d like to fix.</li><li>I’ve seen some systems that use sockets connected to the running setup scripts to give real-time progress updates, instead of relying on a binary HTTP response. I’ve worked with sockets <a href=\"https://penguinegg.com\">before</a>, so I knew that for the first version of the project they would be complicated enough that I wanted to avoid them.</li></ul></article>",
            "url": "https://jameslittle.me/blog/2018/developing-deploying-orient",
            "title": "Developing and Deploying bowdoinorient.com",
            "summary": "An outline of the system I built to spin up temporary, easily-hacked-on versions of bowdoinorient.com",
            "date_modified": "2018-09-14T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2018/learning-making",
            "content_html": "<article><p>I’ve been working on a crossword puzzle creator for about three years, and I can’t tell whether it’s close to done or barely even started. In that time, the project has morphed into a personal playground in which I experiment with new, experimental web technologies. In practical terms, this means I’ve been restarting the project fairly regularly, using a new web framework each time. I've learned how to solve the same problem five different ways. I've rewritten entire UIs as my design chops have improved. I've been learning, but I haven't made any progress. <Footnote>Which leads to fun problems such as <em>”I know I wrote a JSON puzzle parser at some point, but where did it go?”</em></Footnote></p><p>When I realized that this cyclical development was getting problematic, I stepped back and looked at what I was doing. This project had become solely devoted to my own learning: I wasn't building a crossword puzzle anymore, I was using the application design for my own education. My having fallen into this hole wasn't necessarily a bad thing; in fact, there are benefits to experimenting with unknown technologies using a known problem domain. The question, therefore, becomes: <em>which project ideas are better suited as vehicles for learning, and which are better suited for working to completion?</em></p><p>I’ve found that the best tech playgrounds — these venues for experimenting with new tools, concepts, and techniques — are exciting projects with limited (but flexible) scope, that come from ideas you haven’t put any stake in. In other words, productive programming involves separating the learning from the making as much as possible.</p><h2>It's easy to get mixed up</h2><p>Following that advice is hard: my own relationship with writing code blends the learning and making together such that I’m often learning a language while working a new project idea. Motivation to write code often only comes when I’m excited about a project: building my crossword app has only happened because I have a “<em>creating</em>” itch I want to scratch. With that motivation comes grandiose ideas: <em>”What if the whole app used GraphQL?”</em> And thus I find myself struggling with two challenges—implementing a GraphQL server and modeling a crossword puzzle word object—simultaneously.</p><p>There’s only so much time to write code, and doing only the learning or only the making seems redundant or, hate to say it, even boring. This lack of excitement goads me to take on as much as possible in a project. Sometimes still, I’ll get caught up in finding the technology best suited for my project; I’ll explore one until I reach a framework limitation, scrap what I have, and start over using another framework. This gives me the repeated short-term dopamine rush of figuring out a new puzzle while simultaneously ensuring that I never get past more than the first leg of what I set out to do.</p><h2>Separation of Concerns</h2><p>With slightly less excitement—by not taking on too many challenges at once—comes more efficiency and a greater ability to follow through on my initial ideas. I’ve watched this play out in my recent work. The projects I’ve completed recently use technologies with which I was already familiar; the projects that have been stagnating began as overambitious moonshots. When I use a familiar, tried-and-true stack, I don’t find myself struggling to implement a solution after I solve a problem in my head. Instead, the solutions that come to mind are already modeled using the tools I know. There aren’t as many dopamine rushes, but instead of puzzling over how to write code, I’m able to crunch through the project’s challenges instead.</p><p>I have learned to recognize two different mentalities I take on when I’m writing code. The first is one of productivity, in which I’m driven to make something, either by completing or working on a project. The second is one in which I want to scratch a curiosity itch, either by reading about what other people are making, or by investigating whether there is a better way to solve a problem. However, I often have trouble understanding a framework (or language or concept) if I’m just reading about it; I usually need to write code in order to get a sense of what’s going on. When I’m feeling curious, I let myself explore freely. I might get some reading done, watch some videos, and then either start a new project or branch off of an existing one and play around with the code I have no expectation that anything I write will stick. If the code I write is significant, I’ll continue down that path; oftentimes though, I’ll take what I learned and incorporate it into something later. Regardless of the outcome, I have made sure that block of time is set aside for learning, and I use it only to learn, to experiment, to mess around, knowing that when I’m in the mood to create, the familiar project is right where I left it.</p><h2>Ending Thoughts</h2><p>This system isn’t perfect, but I’ve found it helps to split up my time by examining what I want to do with it. When I want to build something, I do so in a way that maximizes efficiency: I use the tools I know to build something I wouldn’t necessarily be able to otherwise. When I want to learn, I let my time become unstructured, full of reading, experimenting, and testing. Sometimes the two blend into each other: a lot of code rewrites have come from learning a better way to solve a problem. However, the familiarity that surrounds me while I’m working on a project lets me focus on the problems I want to solve, instead of having an unknown language, framework, or system create more problems at the start.</p><p>As I work on personal projects in the future, I'll try to think about the goal of the project: am I building this to create, or am I building this to learn? Regardless of the decision—since there is time for both—I'll work with the goal of learning or making as exclusively as possible.</p></article>",
            "url": "https://jameslittle.me/blog/2018/learning-making",
            "title": "Learning and Making",
            "summary": "What kinds of personal projects help you learn best? When can they stall learning? When should you build in order to learn, and when should you build in order to have something built at the end?",
            "date_modified": "2018-06-24T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2018/rss-decentralized-web",
            "content_html": "<article><p><a href=\"https://www.wired.com/story/rss-readers-feedly-inoreader-old-reader/\">Wired</a>, <a href=\"https://www.oreilly.com/ideas/its-time-to-rebuild-the-web\">OReilly</a> <a href=\"https://neflabs.com/blog/rss-renaissance/\">and</a> <a href=\"https://css-tricks.com/its-time-for-an-rss-revival\">others</a> have been publishing articles about the rising potential for an RSS reemergence. RSS, the relatively obscure, techie-centric publishing technology that let users aggregate their own feed of web content, is heralded as a refreshing alternative to contemporary news curation. Today, in the age of a few large internet companies controlling news curation (and therefore, controlling what people read), the above writers (and many others) argue that we need to regain control of our own reading habits by decoupling them from social media; instead, we should curate our own RSS feed subscriptions. By doing this, writers argue, the semi-algorithmic middleman that brings articles to readers will be cut out. Readers will directly (and exclusively) access the content they want to see without being tracked, analyzed, or otherwise judged.</p><p>But the web today is not set up for an RSS revival. RSS itself is an imperfect technology that can be abused by publishers and was abandoned by readers for good reasons. The central problem RSS hopes to solve—over-curation of news—certainly still exists, but RSS is not the right technology to solve it.</p><h2>Limits of RSS guarantee a poor reading experience</h2><p>Publishers have complete control over what goes in their RSS feed, which degrades the usefulness of RSS aggregations and brings about a confusing, dissonant, and inelegant user experience. Without any standardization, users spend more time parsing headlines and clicking on links to seek out what they want to read.</p><h3>Drinking from the Firehose</h3><p>RSS is a technology optimized for readers who subscribe to infrequently-published feeds, every article of which might be worth their attention. Using RSS to read <a href=\"http://daringfireball.net\">Daring Fireball</a>, for example, makes sense: John Gruber publishes only a few times each day, and each post on his blog is—at least for me—worth taking a look at. When I browse his RSS feed, I see a list of content he has published since I <em>last</em> looked at his feed, I open up the articles that pique my interest, and I read them. This is, by all accounts, a pleasurable RSS experience. I see new stuff I want to read, and I read it. But the Daring Fireballs and personal blogs of the world don’t fully encapsulate what I want to read on the internet.</p><p>Major publications have a much harder time wrangling RSS feeds. Ars Technica offers <a href=\"https://arstechnica.com/rss-feeds/\">19 different feeds you can subscribe to</a>, except it’s actually 38 since Ars subscribers can get access to feeds that don’t truncate content. Subscribers to their main feed got fifteen new articles in their RSS readers on April 23, which I argue is too many to be useful. Larger sites are even worse: the New York Times, the Washington Post, CNN, and Reuters each offer dozens of RSS feeds, usually one that publishes everything new and several for each section of the newspaper. Any one of these feeds puts out enough content to drown readers and, since each article in an RSS feed has the same visual weight in an RSS reader application, offers no indication toward what’s actually important. Readers get lost in dozens of unimportant headlines, causing them to miss the ones that are significant.</p><p>It’s hard to assign blame when reading through one’s RSS aggregator feels like drinking from a firehose. In frustration, I’ve unsubscribed from every feed that publishes more articles I skip over than click on. But these major news publications don’t offer a more curated way of browsing through their content, so I feel lost. Publishers could offer <em>more</em> feeds, letting me subscribe to, for example, only the most popular U.S. political news that affects technological and educational infrastructure and innovation. That solution would be hard for users and difficult for publishers. Until news organizations take over curation, Facebook, Twitter, and other services that track my interests and interactions will always be better at realizing that those types of articles are the ones I’m going to engage with.</p><h3>Loss of discoverability</h3><p>One of the reasons social media has become a viable news curation service is because of inter-network sharing: on social media, I read not only content that publishers put out (if I subscribe to a publication’s Facebook or Twitter feed) but also the content my connections are interacting with. I learn about new blogs, new websites, and new publications because they appear on my social media feed relatively unprompted: this lets me feel sufficiently informed.</p><p>RSS has no such discoverability: the feeds I’m subscribed to are the feeds I get. The decentralized nature of RSS means I have no way of seeing what’s popular, what my friends and coworkers will be talking about the next day, what coverage of a certain event went more in depth. In this hypothetical decentralized future internet, discoverability would be the responsibility of individual readers, who might outsource the responsibility to individuals (like Gruber or <a href=\"http://kottke.org\">Jason Kottke</a>) or services (like Reddit, Digg, Hacker News, or Lobsters). This turns discovery into a multi-step, involved process, a process individual readers will not spring at the opportunity to endure.</p><h3>UI Gripes</h3><p>Finally, RSS as a protocol is simultaneously too limiting and too unconstrained. Articles are sent to feed aggregators as bits of HTML, which the aggregator can choose to format however it wants. Assuming a well-designed feed aggregator (which many are not), the restrictiveness of just HTML means that publishers will resort to strange conventions to format articles (like using subheading tags for various organizational purposes) while aggregators will try to find a style that suits each feed equally. Those familiar with discussions around semantic HTML will notice a similarity: an <code>&lt;h2&gt;</code> tag means different things on a website-to-website basis, and will therefore mean different things on a feed-to-feed basis. There isn’t a defined way to style RSS content, so publishers and aggregators have to find an awkward middle ground between design and customizability, which ultimately leads to a mediocre experience for everyone.</p><h2>RSS feed aggregators will become the next social networks</h2><p>RSS aggregator will have to solve the problems of curation, discoverability, and design in order to make RSS a viable replacement for social media news curation, since these are the problems preventing RSS from becoming popular. However, any RSS aggregator that does so will ultimately have to fall into the traps that social media sites have found themselves in. Curation can either be aggregator-led or user-led: user-led curation is often too cumbersome for average users (see also: iTunes Smart Playlists), and aggregator-led curation leads to calls that the aggregator itself is biased. Discoverability, too, is a slippery slope: what will an aggregator deem acceptable and worth highlighting?</p><p>Finally, if an aggregator starts defining more advanced design paradigms, it will either do so from a place of customization (having custom elements in feed entries to define styling that only appears in that specific application) or from a place of dominance (if everyone uses Feedly, for example, Feedly’s styling becomes the de-facto default, and ev). Neither solution is ideal, since both fly in the face of the original issue: the decentralization of media content. If the design of RSS is to be improved without interfering with the openness of the protocol, every publisher and every aggregator will have to agree on a new set of standards.</p><h2>Does RSS have a future?</h2><p>RSS has a place in the publishing world, especially in the space occupied by the Grubers, the Kottkes, and the personal blogs of the world. But for bigger news dominated by larger publications, there needs to be some level of hierarchy, some more advanced design, and some better discoverability. I’m not giving up on social media yet—while the platforms have flaws, they work as surprisingly capable news aggregation services. However, I have been using RSS to supplement: for the articles I don’t want to miss from the publications and writers I want to support.</p></article>",
            "url": "https://jameslittle.me/blog/2018/rss-decentralized-web",
            "title": "Bringing back RSS won't decentralize web publishing.",
            "summary": "The first post I ever wrote, about RSS's place on the internet in the era of online news and content distribution.",
            "date_modified": "2018-04-24T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        },
        {
            "id": "https://jameslittle.me/blog/2018/github-keys",
            "content_html": "<article><p>I generate SSH keys a lot. Here's how to make them (and add them to your Github account) as fast as humanly possible.</p><ol><li>Open <a href=\"https://github.com/settings/ssh/new\">https://github.com/settings/ssh/new</a> in a new tab</li><li>Run <code>ssh-keygen -t rsa -b 4096</code> in your terminal. Make a passphrase. Save the key in the default location.</li><li>Run <code>eval &quot;$(ssh-agent -s)&quot;; ssh-add ~/.ssh/id_rsa; cat ~/.ssh/id_rsa.pub</code></li><li>Copy and paste the terminal output into the Github page you opened before.</li></ol><p>Title format courtesy of <a href=\"https://www.hammacher.com/product/most-efficient-fireplace-grate\">Hammacher Schlemmer</a>.</p></article>",
            "url": "https://jameslittle.me/blog/2018/github-keys",
            "title": "The Most Efficient Github SSH Key Generation Process",
            "summary": "I generate SSH keys a lot. Here's how to make them (and add them to your Github account) as fast as humanly possible.",
            "date_modified": "2018-03-20T00:00:00.000Z",
            "author": {
                "name": "James Little",
                "url": "https://jameslittle.me"
            }
        }
    ]
}